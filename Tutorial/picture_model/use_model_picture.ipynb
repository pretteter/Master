{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import os\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import soundfile as sf\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import shap\n",
    "import gc\n",
    "from collections import Counter\n",
    "from pydub.silence import detect_silence\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import multiprocessing\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import concurrent.futures\n",
    "\n",
    "import json\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import csv\n",
    "\n",
    "\n",
    "# DATA_DIR = pathlib.Path('data')\n",
    "# TEST_DIR = pathlib.Path('data/new_test')\n",
    "\n",
    "ROOT_DIR = Path('../').resolve()  \n",
    "UNZIP_DIR = ROOT_DIR / 'Unzipped_Data_Picture' \n",
    "TEST_DIR = ROOT_DIR / UNZIP_DIR / 'new_test'\n",
    "# TEST_DIR = ROOT_DIR / UNZIP_DIR / 'new_test_2'\n",
    "# TEST_DIR = ROOT_DIR / UNZIP_DIR / 'new_test_3'\n",
    "# TEST_DIR = ROOT_DIR / UNZIP_DIR / 'final_test'\n",
    "\n",
    "_zip_file_path = \"model_results/model_(10112_256px-resnet_model)_loss_0.215_acc_0.863_val_loss_1.141_val_acc_0.773.zip\"\n",
    "\n",
    "session = None\n",
    "max_length = 0\n",
    "downsize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip(zip_path, extract_to):\n",
    "    zip_path_str = str(zip_path)\n",
    "    \n",
    "    if not zip_path_str.endswith('.zip'):\n",
    "        zip_path_str += '.zip'\n",
    "    \n",
    "    zip_file_path = pathlib.Path(zip_path_str)\n",
    "    \n",
    "    folder_name = zip_file_path.stem \n",
    "    target_folder = pathlib.Path(extract_to) / folder_name\n",
    "    \n",
    "    if target_folder.exists():\n",
    "        print(f\"Das Verzeichnis {target_folder} existiert bereits. Überspringe das Extrahieren.\")\n",
    "    else:\n",
    "        if zip_file_path.exists():\n",
    "            print(f\"Extrahiere die Zip-Datei {zip_file_path} nach {extract_to}.\")\n",
    "            with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extract_to)\n",
    "            print(f\"Zip-Datei {zip_file_path} erfolgreich extrahiert.\")\n",
    "        else:\n",
    "            print(f\"Die Zip-Datei {zip_file_path} existiert nicht.\")\n",
    "\n",
    "def rename_audio_files(root_path):\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        parent_folder = os.path.basename(root)\n",
    "        for file in files:\n",
    "            if not file.startswith(f\"{parent_folder}_\"):\n",
    "                if file.endswith(('.wav', '.mp3')):  \n",
    "                    \n",
    "                    old_file_path = os.path.join(root, file)\n",
    "                    new_file_name = f\"{parent_folder}_{file}\"\n",
    "                    new_file_path = os.path.join(root, new_file_name)\n",
    "                        \n",
    "                    os.rename(old_file_path, new_file_path)\n",
    "        print(f\"renaming of {root_path}/{parent_folder} complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_audio_length(input_dir):\n",
    "    output_dir = input_dir.parent / f\"{input_dir.name}_normalized\"\n",
    "    if output_dir.exists():\n",
    "        print(f\"Überspringe Verarbeitung, da {output_dir} bereits existiert.\")\n",
    "        return output_dir\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    max_length = session.get(\"max_length\", 0)\n",
    "    print(f\"max_length : {max_length}\")\n",
    "    audio_files = []\n",
    "    \n",
    "    for subdir, _, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                input_path = Path(subdir) / file\n",
    "                audio = AudioSegment.from_file(input_path)\n",
    "                duration = len(audio)\n",
    "                audio_files.append((input_path, audio))\n",
    "    \n",
    "    print(f\"Maximale Länge: {max_length / 1000} Sekunden\")\n",
    "    \n",
    "    for input_path, audio in audio_files:\n",
    "        if len(audio) > max_length:\n",
    "            print(f\"⚠️ {input_path.name} ist länger als {max_length / 1000} Sekunden. Kürze Datei!\")\n",
    "            audio = audio[:max_length] \n",
    "\n",
    "        padded_audio = audio + AudioSegment.silent(duration=max(0, max_length - len(audio)))\n",
    "        \n",
    "        relative_path = input_path.parent.relative_to(input_dir)\n",
    "        target_dir = output_dir / relative_path\n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "        output_path = target_dir / input_path.name\n",
    "        \n",
    "        padded_audio.export(output_path, format=\"wav\")\n",
    "        print(f\"Processed {input_path.name}: expanded to {max_length / 1000} seconds\")\n",
    "    \n",
    "    print(f\"Processing complete. Normalized files saved in {output_dir}\")\n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_file(audio_file, input_dir, output_dir, n_mels, fmin, fmax):\n",
    "    \"\"\"\n",
    "    Diese Funktion verarbeitet eine einzelne Audiodatei und berechnet das Mel-Spektrogramm.\n",
    "    \"\"\"\n",
    "    relative_path = audio_file.relative_to(input_dir)\n",
    "    \n",
    "    target_dir = output_dir / relative_path.parent\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    y, sr = librosa.load(audio_file, sr=44100)\n",
    "\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, fmin=fmin, fmax=fmax)\n",
    "\n",
    "\n",
    "    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "    return relative_path, mel_spectrogram, sr, target_dir, audio_file.stem\n",
    "\n",
    "def generate_mel_spectrograms_with_structure(input_dir, output_dir, n_mels=256, fmin=20, fmax=44100, batch_size=25, square = False):\n",
    "    \"\"\"\n",
    "    Optimierte Funktion für die Verarbeitung von Mel-Spektrogrammen:\n",
    "    1. Berechnung wird parallelisiert.\n",
    "    2. Ergebnisse werden sequentiell geplottet, um Thread-Sicherheitsprobleme zu vermeiden.\n",
    "    3. Batches werden verwendet, um den Speicherverbrauch zu kontrollieren.\n",
    "    \"\"\"\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "\n",
    "    if output_dir.exists() and any(output_dir.rglob(\"*.png\")):\n",
    "        print(f\"Überspringe Verarbeitung, da {output_dir} bereits Mel-Spektrogramme enthält.\")\n",
    "        return\n",
    "\n",
    "    audio_files = list(input_dir.rglob(\"*.wav\"))\n",
    "\n",
    "    if not audio_files:\n",
    "        print(\"Keine Audiodateien gefunden.\")\n",
    "        return\n",
    "\n",
    "    total_files = len(audio_files)\n",
    "    print(f\"{total_files} Audiodateien gefunden. Verarbeitung startet.\")\n",
    "\n",
    "    for batch_start in range(0, total_files, batch_size):\n",
    "        batch_files = audio_files[batch_start:batch_start + batch_size]\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.close('all')\n",
    "        gc.collect()\n",
    "        print(f\"Verarbeite Batch {batch_start // batch_size + 1} von {total_files // batch_size + 1}\")\n",
    "\n",
    "        results = []\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = [\n",
    "                executor.submit(process_audio_file, audio_file, input_dir, output_dir, n_mels, fmin, fmax)\n",
    "                for audio_file in batch_files\n",
    "            ]\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                results.append(future.result())\n",
    "\n",
    "        for relative_path, mel_spectrogram_db, sr, target_dir, audio_file_stem in results:\n",
    "            mel_spectrogram_path = target_dir / f\"{audio_file_stem}_mel_spectrogram.png\"\n",
    "\n",
    "            if mel_spectrogram_path.exists():\n",
    "                print(f\"Spektrogramm {mel_spectrogram_path} existiert bereits. Überspringen.\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                if square:\n",
    "                    plt.figure(figsize=(2, 2))\n",
    "                    librosa.display.specshow(mel_spectrogram_db, x_axis='time', y_axis='mel', sr=sr, cmap='magma', fmin=fmin, fmax=fmax)\n",
    "                    plt.axis('off')\n",
    "\n",
    "                    plt.savefig(mel_spectrogram_path, bbox_inches='tight', pad_inches=0, dpi=300)\n",
    "                    plt.close()\n",
    "                    print(f\"{batch_start // batch_size + 1} von {total_files // batch_size + 1}__Mel-Spektrogramm für {audio_file_stem} gespeichert in {mel_spectrogram_path}\")\n",
    "                else:\n",
    "                    height = 333 if downsize else 2000 \n",
    "                    width = height * 30 \n",
    "                    dpi = 100  \n",
    "                    figsize = (width / dpi, height / dpi)\n",
    "\n",
    "                    fig, ax = plt.subplots(figsize=figsize, dpi=dpi, frameon=False)\n",
    "\n",
    "                    librosa.display.specshow(mel_spectrogram_db, x_axis='time', y_axis='mel', sr=sr, cmap='magma', fmin=fmin, fmax=fmax)\n",
    "                    ax.set_axis_off()\n",
    "\n",
    "                    plt.savefig(mel_spectrogram_path, bbox_inches='tight', pad_inches=0, dpi=dpi)\n",
    "                    plt.close(fig)\n",
    "                    print(f\"{batch_start // batch_size + 1} von {total_files // batch_size + 1}__Mel-Spektrogramm für {audio_file_stem} gespeichert in {mel_spectrogram_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Fehler beim Plotten von {audio_file_stem}: {e}\")\n",
    "            finally:\n",
    "                del mel_spectrogram_db\n",
    "\n",
    "    print(f\"Alle Mel-Spektrogramme gespeichert in {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_spectrogram(image_path, output_dir):\n",
    "    \"\"\"\n",
    "    Schneidet ein Spektrogramm in gleich große Quadrate.\n",
    "    :param image_path: Pfad zum Spektrogramm (PNG)\n",
    "    :param output_dir: Ordner zum Speichern der Segmente\n",
    "    :param segment_size: Größe jedes quadratischen Segments (Standard: 924x924)\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    trash_dir = output_dir.parent.parent / f\"{output_dir.parent.name}_trash\"\n",
    "    os.makedirs(trash_dir, exist_ok=True)\n",
    "\n",
    "    img = Image.open(image_path)\n",
    "    width, height = img.size\n",
    "    segment_size = height\n",
    "\n",
    "    num_segments = width // segment_size - 1\n",
    "    for i in range(1, num_segments):\n",
    "        left = i * segment_size\n",
    "        right = left + segment_size\n",
    "        segment = img.crop((left, 0, right, segment_size))\n",
    "        segment_array = np.array(segment)\n",
    "\n",
    "        silence_threshold = 10  \n",
    "        silence_ratio = np.mean(segment_array < silence_threshold)\n",
    "\n",
    "        transparency_ratio = 0\n",
    "        if segment.mode == 'RGBA':\n",
    "            alpha_channel = segment_array[:, :, 3] \n",
    "            transparency_ratio = np.mean(alpha_channel == 0)  \n",
    "\n",
    "        output_path = Path(output_dir) / f\"{Path(image_path).stem}_part{i}.png\"\n",
    "        if silence_ratio >= 0.7 or transparency_ratio > 0.2:\n",
    "            output_path = trash_dir / f\"{Path(image_path).stem}_part{i}.png\"\n",
    "            print(f\"Segment {i} enthält {silence_ratio * 100:.2f}% Stille und wird in den Trash {output_path} verschoben.\")\n",
    "        \n",
    "        try:\n",
    "            segment.save(output_path)\n",
    "        except IOError:\n",
    "            print(f\"Fehler beim Speichern des Segments: {output_path}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"Spektrogramm in {num_segments} Segmente geschnitten und gespeichert in {output_dir}\")\n",
    "\n",
    "\n",
    "def process_spectrograms(input_dir):\n",
    "    \"\"\"\n",
    "    Verarbeitet Spektrogramme im angegebenen Verzeichnis, ohne Unterverzeichnisse zu durchsuchen.\n",
    "    Jedes Spektrogramm wird in einem eigenen Unterordner gespeichert.\n",
    "    :param input_dir: Verzeichnis mit Spektrogrammen\n",
    "    \"\"\"\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = input_dir.parent / f\"{input_dir.name}_splits\"\n",
    "    \n",
    "    if output_dir.exists():\n",
    "        print(f\"Output directory already exists: {output_dir}. Skipping splitting.\")\n",
    "        return output_dir\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for image_path in input_dir.glob(\"*.png\"): \n",
    "        subdir_name = image_path.stem.replace(\"_mel_spectrogram\", \"\")\n",
    "        target_dir = output_dir / subdir_name  \n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            img = Image.open(image_path)\n",
    "            img.verify() \n",
    "            split_spectrogram(image_path, target_dir) \n",
    "        except (IOError, SyntaxError):\n",
    "            print(f\"Fehler: Beschädigtes oder ungültiges Bild übersprungen: {image_path}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        if not any(target_dir.iterdir()):\n",
    "            os.rmdir(target_dir)\n",
    "            print(f\"Leerer Ordner {target_dir} wurde gelöscht.\")\n",
    "\n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_table(table, df=None):\n",
    "    for (i, j), cell in table.get_celld().items():\n",
    "        if i == 0: \n",
    "            cell.set_fontsize(12)\n",
    "            cell.set_text_props(weight='bold')\n",
    "            cell.set_facecolor('#d3d3d3')  \n",
    "\n",
    "        elif df is not None and i > 0 and j < len(df.columns):  \n",
    "            if j == 0:  \n",
    "                cell.set_facecolor('#f0f8ff')  \n",
    "\n",
    "            elif j == 1 or j == 2:  \n",
    "                true_class = df.iloc[i - 1][\"True Class\"]  \n",
    "                predicted_class = df.iloc[i - 1][\"Predicted Class\"]\n",
    "\n",
    "  \n",
    "                if true_class == predicted_class:\n",
    "                    cell.set_facecolor('#d4edda')  \n",
    "                else:\n",
    "                    cell.set_facecolor('#f8d7da') \n",
    "                cell.set_fontsize(10)\n",
    "\n",
    "            else: \n",
    "                try:\n",
    "                    if float(cell.get_text().get_text()) < 0.5:\n",
    "                        cell.set_facecolor('#f8d7da')  \n",
    "                    else:\n",
    "                        cell.set_facecolor('#d4edda')  \n",
    "                except ValueError:\n",
    "                    pass \n",
    "            cell.set_fontsize(10)\n",
    "\n",
    "    return table\n",
    "\n",
    "\n",
    "\n",
    "def generate_summary(results):\n",
    "    total_predictions = len(results)\n",
    "    correct_predictions = sum(1 for result in results if result['True Class'].split()[0] == result['Predicted Class'].split()[0]) \n",
    "    accuracy = correct_predictions / total_predictions * 100\n",
    "\n",
    "    correct_original = sum(1 for result in results if result['True Class'].split()[0] == 'original' and result['Predicted Class'].split()[0] == 'original')\n",
    "    correct_upscale = sum(1 for result in results if result['True Class'].split()[0] == 'upscale-from-mp3-128' and result['Predicted Class'].split()[0] == 'upscale-from-mp3-128')\n",
    "    \n",
    "    original_accuracy = correct_original / sum(1 for result in results if result['True Class'].split()[0] == 'original') * 100 if sum(1 for result in results if result['True Class'].split()[0] == 'original') > 0 else 0\n",
    "    upscale_accuracy = correct_upscale / sum(1 for result in results if result['True Class'].split()[0] == 'upscale-from-mp3-128') * 100 if sum(1 for result in results if result['True Class'].split()[0] == 'upscale-from-mp3-128') > 0 else 0\n",
    "\n",
    "    summary = {\n",
    "        \"Total Correct\": f\"{correct_predictions} / {total_predictions} ({accuracy:.2f}%)\",\n",
    "        \"Original Accuracy\": f\"{original_accuracy:.2f}%\",\n",
    "        \"Upscale Accuracy\": f\"{upscale_accuracy:.2f}%\",\n",
    "        \"Overall Accuracy\": f\"{accuracy:.2f}%\",\n",
    "    }\n",
    "\n",
    "    return summary\n",
    "\n",
    "def display_summary(summary):\n",
    "    summary_data = [\n",
    "        [\"Total Correct\", summary[\"Total Correct\"]],\n",
    "        [\"Original Accuracy\", summary[\"Original Accuracy\"]],\n",
    "        [\"Upscale Accuracy\", summary[\"Upscale Accuracy\"]],\n",
    "        [\"Overall Accuracy\", summary[\"Overall Accuracy\"]]\n",
    "    ]\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data, columns=[f\"Parameter\", \"Value\"])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 2))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "\n",
    "    table = ax.table(cellText=summary_df.values, colLabels=summary_df.columns, cellLoc=\"center\", loc=\"center\", colWidths=[0.5, 0.5])\n",
    "    \n",
    "    color_table(table)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return fig\n",
    "\n",
    "def calculate_accuracy(results):\n",
    "    \"\"\"\n",
    "    Berechnet die Anzahl korrekt und falsch klassifizierter Dateien basierend auf den Ergebnissen.\n",
    "    Erwartet eine Liste von Dictionaries mit den Schlüsseln 'True Class' und 'Predicted Class'.\n",
    "    \"\"\"\n",
    "    correct_predictions = sum(1 for result in results if result['True Class'] == result['Predicted Class'])\n",
    "    total_predictions = len(results)\n",
    "    accuracy = correct_predictions / total_predictions * 100\n",
    "    print(f\"Korrekte Vorhersagen: {correct_predictions}\")\n",
    "    print(f\"Falsche Vorhersagen: {total_predictions - correct_predictions}\")\n",
    "    print(f\"Genauigkeit: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "def save_results(zip_file_path, table_figure, summary_figure):\n",
    "    base_name = os.path.splitext(os.path.basename(zip_file_path))[0]\n",
    "    output_dir = os.path.dirname(zip_file_path)\n",
    "\n",
    "    table_image_path = os.path.join(output_dir, f\"{base_name}_table.png\")\n",
    "    summary_image_path = os.path.join(output_dir, f\"{base_name}_summary.png\")\n",
    "\n",
    "    if not os.path.exists(table_image_path):\n",
    "        table_figure.savefig(table_image_path, bbox_inches=\"tight\")\n",
    "        print(f\"Haupttabelle als Bild gespeichert: {table_image_path}\")\n",
    "    else:\n",
    "        print(f\"Haupttabelle übersprungen (bereits vorhanden): {table_image_path}\")\n",
    "\n",
    "    if not os.path.exists(summary_image_path):\n",
    "        summary_figure.savefig(summary_image_path, bbox_inches=\"tight\")\n",
    "        print(f\"Zusammenfassungstabelle als Bild gespeichert: {summary_image_path}\")\n",
    "    else:\n",
    "        print(f\"Zusammenfassungstabelle übersprungen (bereits vorhanden): {summary_image_path}\")\n",
    "\n",
    "\n",
    "def load_model_and_session(zip_file_path):\n",
    "    \"\"\"Lädt das Modell und die Session-Daten aus einer ZIP-Datei.\"\"\"\n",
    "    extract_path = \"restored_model\"\n",
    "\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "\n",
    "    model_path = f\"{extract_path}/model.h5\"\n",
    "    loaded_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    session_data_path = f\"{extract_path}/session_data.json\"\n",
    "    if os.path.exists(session_data_path):\n",
    "        try:\n",
    "            with open(session_data_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "                session_data = json.load(json_file)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Fehler: Die JSON-Datei ist fehlerhaft oder beschädigt.\")\n",
    "            session_data = {} \n",
    "        except Exception as e:\n",
    "            print(f\"Ein unerwarteter Fehler ist aufgetreten: {e}\")\n",
    "            session_data = {}\n",
    "    else:\n",
    "        print(\"Warnung: Die Datei existiert nicht.\")\n",
    "        session_data = {}\n",
    "\n",
    "    return loaded_model, session_data\n",
    "\n",
    "\n",
    "\n",
    "def predict_with_model(model, splits_dir):\n",
    "    \"\"\"\n",
    "    Durchläuft alle Spektrogramm-Splits eines Tracks (Ordners),\n",
    "    berechnet die Vorhersagen und gibt den Durchschnitt zurück.\n",
    "    \n",
    "    :param model: Das geladene Modell für die Vorhersage\n",
    "    :param splits_dir: Pfad zum Ordner mit den Spektrogramm-Splits\n",
    "    :return: Durchschnittliche Vorhersage für den gesamten Track\n",
    "    \"\"\"\n",
    "    splits_dir = Path(splits_dir)\n",
    "    if not splits_dir.exists() or not splits_dir.is_dir():\n",
    "        raise ValueError(f\"Das Verzeichnis {splits_dir} existiert nicht oder ist kein Verzeichnis.\")\n",
    "    \n",
    "    input_shape = model.input_shape \n",
    "    _, target_height, target_width, _ = input_shape  \n",
    "    print(f\"Erwartete Bildgröße: {target_height} x {target_width}\")\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for image_path in splits_dir.glob(\"*.png\"):  \n",
    "        image = Image.open(image_path).convert(\"RGB\") \n",
    "        if downsize:\n",
    "            image = image.resize((256, 256))  \n",
    "        else: \n",
    "            image = image.resize((target_width, target_height))\n",
    "\n",
    "        image_array = np.array(image)  \n",
    "        input_data = tf.convert_to_tensor(image_array, dtype=tf.float32)\n",
    "        input_data = np.expand_dims(image_array, axis=0)  \n",
    "        \n",
    "        pred = model.predict(input_data)[0]\n",
    "        print(f\"Vorhersage für {image_path}: {pred}\")\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    if not predictions:\n",
    "        raise ValueError(f\"Keine validen Spektrogramm-Splits in {splits_dir} gefunden.\")\n",
    "    \n",
    "    avg_prediction = np.mean(predictions, axis=0)  \n",
    "    print(f\"Durchschnittliche Vorhersage für {splits_dir.name}: {avg_prediction}\")\n",
    "    \n",
    "    return avg_prediction\n",
    "\n",
    "\n",
    "def run(zip_file_path = None, _downsize = False):\n",
    "    extract_zip(TEST_DIR, UNZIP_DIR)\n",
    "    global session, downsize, _zip_file_path\n",
    "    downsize = _downsize\n",
    "    if zip_file_path is None:\n",
    "        zip_file_path = _zip_file_path\n",
    "\n",
    "    model, session = load_model_and_session(zip_file_path)\n",
    "    print(f\"Model loaded from: {zip_file_path}\")\n",
    "    print (f\"Session : {session}\")\n",
    "    \n",
    "    audio_dir = TEST_DIR\n",
    "\n",
    "    path = normalize_audio_length(Path(audio_dir))\n",
    "    test_mel_dir = Path(f\"{path.stem}_mel_spectrograms\" + (\"_downsize\" if downsize else \"\"))\n",
    "    generate_mel_spectrograms_with_structure(path,test_mel_dir)\n",
    "    test_mel_dir = process_spectrograms(test_mel_dir)\n",
    "\n",
    "    results = []\n",
    "    class_names = [\"original\", \"upscale-from-mp3-128\"]\n",
    "    \n",
    "    for track_dir in Path(test_mel_dir).iterdir():\n",
    "        if track_dir.is_dir():\n",
    "            if not any(track_dir.iterdir()):\n",
    "                print(f\"Überspringe leeres Verzeichnis: {track_dir}\")\n",
    "                continue\n",
    "            \n",
    "            if \"orig-16-44-mono\" in track_dir.name:\n",
    "                true_class = \"original\"\n",
    "            elif \"upscale-from-mp3-128\" in track_dir.name:\n",
    "                true_class = \"upscale-from-mp3-128\"\n",
    "            elif \"upscale-from-aac-128\" in track_dir.name:\n",
    "                true_class = \"upscale-from-aac-128\"\n",
    "            else:\n",
    "                raise ValueError(f\"Unbekannte Klasse im Ordnernamen: {track_dir.name}\")\n",
    "            \n",
    "            predictions = predict_with_model(model, track_dir)\n",
    "            predicted_class_index = np.argmax(predictions)\n",
    "            predicted_class = class_names[predicted_class_index]\n",
    "            class_probabilities = {class_names[i]: predictions[i] for i in range(len(predictions))}\n",
    "            \n",
    "            true_class_with_prob = f\"{true_class} ({class_probabilities.get(true_class, 0.0):.4f})\"\n",
    "            predicted_class_with_prob = f\"{predicted_class} ({class_probabilities[predicted_class]:.4f})\"\n",
    "            \n",
    "            results.append({\n",
    "                \"Track_Dir\": track_dir.name,\n",
    "                \"True Class\": true_class_with_prob,\n",
    "                \"Predicted Class\": predicted_class_with_prob\n",
    "            })\n",
    "           \n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, len(df) * 0.4))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "\n",
    "    cell_text = [\n",
    "        [str(value) if isinstance(value, str) else f\"{value:.4f}\" for value in row]\n",
    "        for row in df.values\n",
    "    ]\n",
    "\n",
    "    table = ax.table(\n",
    "        cellText=cell_text,\n",
    "        colLabels=df.columns,\n",
    "        cellLoc=\"center\",\n",
    "        loc=\"center\",\n",
    "        colWidths=[0.5] + [0.25] * (len(df.columns) - 1)\n",
    "    )\n",
    "    \n",
    "    for row in range(len(df)):\n",
    "        cell = table[(row + 1, 0)]\n",
    "        cell.get_text().set_ha('left')\n",
    "\n",
    "    table = color_table(table, df)\n",
    "\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1.2, 1.2) \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    print(results)\n",
    "    summary = generate_summary(results)\n",
    "    summary_figure = display_summary(summary)\n",
    "\n",
    "    save_results(zip_file_path, fig, summary_figure)\n",
    "    shutil.rmtree(\"restored_model\")\n",
    "\n",
    "\n",
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
