{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2049261682.py, line 182)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 182\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(f\"use shape: \"input_shape)\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import soundfile as sf\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "DATA_DIR = pathlib.Path('data')\n",
    "TEST_DIR = pathlib.Path('data/test')\n",
    "seconds = None\n",
    "\n",
    "\n",
    "def color_table(table, df=None):\n",
    "    # Tabelle verschönern: Farben hinzufügen\n",
    "    for (i, j), cell in table.get_celld().items():\n",
    "        if i == 0:  # Titelzeile\n",
    "            cell.set_fontsize(12)\n",
    "            cell.set_text_props(weight='bold')\n",
    "            cell.set_facecolor('#d3d3d3')  # Heller Hintergrund für die Titelzeile\n",
    "\n",
    "        elif df is not None and i > 0 and j < len(df.columns):  # Sicherstellen, dass Spalten existieren\n",
    "            if j == 0:  # Dateiname-Spalte\n",
    "                cell.set_facecolor('#f0f8ff')  # Blauer Hintergrund für die Dateinamen\n",
    "\n",
    "            elif j == 1 or j == 2:  # True Class (Spalte 1) oder Predicted Class (Spalte 2)\n",
    "                true_class = df.iloc[i - 1][\"True Class\"]  # i-1, weil i=0 die Kopfzeile ist\n",
    "                predicted_class = df.iloc[i - 1][\"Predicted Class\"]\n",
    "\n",
    "                # Überprüfe, ob die Vorhersage korrekt ist\n",
    "                if true_class == predicted_class:\n",
    "                    cell.set_facecolor('#d4edda')  # Grün für richtig\n",
    "                else:\n",
    "                    cell.set_facecolor('#f8d7da')  # Rot für falsch\n",
    "                cell.set_fontsize(10)\n",
    "\n",
    "            else:  # Wahrscheinlichkeiten und andere Werte\n",
    "                try:\n",
    "                    if float(cell.get_text().get_text()) < 0.5:\n",
    "                        cell.set_facecolor('#f8d7da')  # Rot, wenn Wahrscheinlichkeit < 0.5\n",
    "                    else:\n",
    "                        cell.set_facecolor('#d4edda')  # Grün, wenn Wahrscheinlichkeit >= 0.5\n",
    "                except ValueError:\n",
    "                    pass  # Ignoriert nicht-numerische Werte\n",
    "            cell.set_fontsize(10)\n",
    "\n",
    "    return table\n",
    "\n",
    "\n",
    "def get_middle_chunk(file_path, chunk_length_seconds):\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    chunk_length_ms = chunk_length_seconds * 1000\n",
    "    total_length_ms = len(audio)\n",
    "    \n",
    "    if total_length_ms <= chunk_length_ms:\n",
    "        return audio\n",
    "    \n",
    "    # Berechne den Startpunkt für den mittleren Chunk\n",
    "    start_point = (total_length_ms - chunk_length_ms) // 2\n",
    "    return audio[start_point:start_point + chunk_length_ms]\n",
    "\n",
    "\n",
    "def generate_summary(results):\n",
    "    total_predictions = len(results)\n",
    "    correct_predictions = sum(1 for result in results if result['True Class'].split()[0] == result['Predicted Class'].split()[0])  # Vergleiche nur die Klassennamen\n",
    "    accuracy = correct_predictions / total_predictions * 100\n",
    "\n",
    "    # Extrahiere die Klassennamen ohne die numerischen Werte\n",
    "    correct_original = sum(1 for result in results if result['True Class'].split()[0] == 'original' and result['Predicted Class'].split()[0] == 'original')\n",
    "    correct_upscale = sum(1 for result in results if result['True Class'].split()[0] == 'upscale-from-mp3-128' and result['Predicted Class'].split()[0] == 'upscale-from-mp3-128')\n",
    "    \n",
    "    # Berechne die Genauigkeit nur für die jeweilige Klasse, falls es Beispiele gibt\n",
    "    original_accuracy = correct_original / sum(1 for result in results if result['True Class'].split()[0] == 'original') * 100 if sum(1 for result in results if result['True Class'].split()[0] == 'original') > 0 else 0\n",
    "    upscale_accuracy = correct_upscale / sum(1 for result in results if result['True Class'].split()[0] == 'upscale-from-mp3-128') * 100 if sum(1 for result in results if result['True Class'].split()[0] == 'upscale-from-mp3-128') > 0 else 0\n",
    "\n",
    "    summary = {\n",
    "        \"Total Correct\": f\"{correct_predictions} / {total_predictions} ({accuracy:.2f}%)\",\n",
    "        \"Original Accuracy\": f\"{original_accuracy:.2f}%\",\n",
    "        \"Upscale Accuracy\": f\"{upscale_accuracy:.2f}%\",\n",
    "        \"Overall Accuracy\": f\"{accuracy:.2f}%\",\n",
    "    }\n",
    "\n",
    "    return summary\n",
    "\n",
    "# Funktion zur Erstellung der Zusammenfassungs-Tabelle\n",
    "def display_summary(summary):\n",
    "    summary_data = [\n",
    "        [\"Total Correct\", summary[\"Total Correct\"]],\n",
    "        [\"Original Accuracy\", summary[\"Original Accuracy\"]],\n",
    "        [\"Upscale Accuracy\", summary[\"Upscale Accuracy\"]],\n",
    "        [\"Overall Accuracy\", summary[\"Overall Accuracy\"]]\n",
    "    ]\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data, columns=[f\"Metric with {seconds}-sec duration\", \"Value\"])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 2))  # Größe der Tabelle\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "\n",
    "    table = ax.table(cellText=summary_df.values, colLabels=summary_df.columns, cellLoc=\"center\", loc=\"center\", colWidths=[0.5, 0.5])\n",
    "    \n",
    "    color_table(table)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return fig\n",
    "\n",
    "def calculate_accuracy(results):\n",
    "    \"\"\"\n",
    "    Berechnet die Anzahl korrekt und falsch klassifizierter Dateien basierend auf den Ergebnissen.\n",
    "    Erwartet eine Liste von Dictionaries mit den Schlüsseln 'True Class' und 'Predicted Class'.\n",
    "    \"\"\"\n",
    "    correct_predictions = sum(1 for result in results if result['True Class'] == result['Predicted Class'])\n",
    "    total_predictions = len(results)\n",
    "    accuracy = correct_predictions / total_predictions * 100\n",
    "    print(f\"Korrekte Vorhersagen: {correct_predictions}\")\n",
    "    print(f\"Falsche Vorhersagen: {total_predictions - correct_predictions}\")\n",
    "    print(f\"Genauigkeit: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "def save_results(zip_file_path, table_figure, summary_figure):\n",
    "    # Extrahiere den Dateinamen ohne Erweiterung aus dem zip_file_path\n",
    "    base_name = os.path.splitext(os.path.basename(zip_file_path))[0]\n",
    "    output_dir = os.path.dirname(zip_file_path)\n",
    "\n",
    "    # Pfade für die beiden PNG-Dateien erstellen\n",
    "    table_image_path = os.path.join(output_dir, f\"{base_name}_table.png\")\n",
    "    summary_image_path = os.path.join(output_dir, f\"{base_name}_summary.png\")\n",
    "\n",
    "    # Speichern der Haupttabelle als Bild, wenn sie nicht existiert\n",
    "    if not os.path.exists(table_image_path):\n",
    "        table_figure.savefig(table_image_path, bbox_inches=\"tight\")\n",
    "        print(f\"Haupttabelle als Bild gespeichert: {table_image_path}\")\n",
    "    else:\n",
    "        print(f\"Haupttabelle übersprungen (bereits vorhanden): {table_image_path}\")\n",
    "\n",
    "    # Speichern der Zusammenfassungstabelle als Bild, wenn sie nicht existiert\n",
    "    if not os.path.exists(summary_image_path):\n",
    "        summary_figure.savefig(summary_image_path, bbox_inches=\"tight\")\n",
    "        print(f\"Zusammenfassungstabelle als Bild gespeichert: {summary_image_path}\")\n",
    "    else:\n",
    "        print(f\"Zusammenfassungstabelle übersprungen (bereits vorhanden): {summary_image_path}\")\n",
    "\n",
    "\n",
    "def load_model(zip_file_path):\n",
    "    \"\"\"Lädt das Modell aus einer ZIP-Datei.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"restored_model\")\n",
    "    model_path = \"restored_model/model.h5\"  # Pfad zur .h5-Datei\n",
    "    loaded_model = tf.keras.models.load_model(model_path)\n",
    "    return loaded_model\n",
    "\n",
    "# def save_spectrogram(spectrogram, export_path):\n",
    "#     \"\"\"Speichert ein Mel-Spektrogramm als Bild.\"\"\"\n",
    "#     plt.figure(figsize=(2.56, 2.56), dpi=100)  # Größe so anpassen, dass das Bild quadratisch ist (128x128)\n",
    "#     plt.axis('off')  # Achsen entfernen\n",
    "#     plt.imshow(spectrogram, aspect='auto', origin='lower', cmap='viridis')\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(export_path, bbox_inches='tight', pad_inches=0)\n",
    "#     plt.close()\n",
    "\n",
    "# def load_spectrogram(image_path):\n",
    "#     \"\"\"Lädt ein gespeichertes Spektrogramm-Bild.\"\"\"\n",
    "#     image = Image.open(image_path).convert(\"RGB\")\n",
    "#     image = image.resize((128, 128))  # Sicherstellen, dass die Größe korrekt ist\n",
    "#     image = np.array(image) / 255.0  # Normalisieren (auf den Wertebereich 0-1)\n",
    "#     return image\n",
    "\n",
    "def predict_with_model(model, audio_path, export_path=\"mel_spectrogram.png\"):\n",
    "    \"\"\"Verarbeitet die Vorhersage für eine Audiodatei und exportiert das Spektrogramm.\"\"\"\n",
    "    input_shape = model.input_shape  # Erwartetes Shape (None, H, W, 3)\n",
    "    _, target_height, target_width, _ = input_shape  # Extrahiere H & W\n",
    "    # Lade die Audiodaten\n",
    "    audio_data, sr = librosa.load(audio_path, sr=None)\n",
    "    print(f\"use shape: {input_shape}\")\n",
    "\n",
    "    # Trimme die Audiodaten auf die Null-Durchgänge\n",
    "    start_sample = librosa.zero_crossings(audio_data, pad=False).argmax()\n",
    "    end_sample = len(audio_data) - librosa.zero_crossings(audio_data[::-1], pad=False).argmax()\n",
    "    audio_data = audio_data[start_sample:end_sample]\n",
    "\n",
    "    # Erstelle das Mel-Spektrogramm\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sr)\n",
    "\n",
    "    # Normalisiere das Spektrogramm\n",
    "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "    # Speichere das Spektrogramm als Bild im Magma-Farbschema\n",
    "    figsize = (target_width / 100, target_height / 100)\n",
    "    plt.figure(figsize=figsize, dpi=100)\n",
    "    plt.axis('off')\n",
    "    librosa.display.specshow(mel_spectrogram_db, cmap='magma', x_axis=None, y_axis=None)\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig(export_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.savefig(export_path, bbox_inches='tight', pad_inches=0, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Spektrogramm gespeichert unter: {export_path}\")\n",
    "\n",
    "    # Lade das gespeicherte Bild\n",
    "    image = Image.open(export_path).convert(\"RGB\")  # Lade als RGB-Bild\n",
    "    image = image.resize((target_width, target_height))\n",
    "    loaded_spectrogram = np.array(image) / 255.0  # Normalisieren auf [0, 1]\n",
    "\n",
    "    # Batch-Dimension hinzufügen (1, 128, 128, 3)\n",
    "    input_data = np.expand_dims(loaded_spectrogram, axis=0)\n",
    "\n",
    "    # Vorhersage durchführen\n",
    "    predictions = model.predict(input_data)[0]\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def run(zip_file_path = \"model_results/test.zip\", _seconds = None):\n",
    "    global seconds \n",
    "    seconds=_seconds\n",
    "    \n",
    "    loaded_model = load_model(zip_file_path)\n",
    "    print(f\"Model loaded from: {zip_file_path}\")\n",
    "\n",
    "    \n",
    "    audio_dir = \"../data/test/\"\n",
    "    results = []\n",
    "    print(f\"Split test files in {seconds}\") if seconds else print(\"Use complete files\")\n",
    "\n",
    "    for audio_file in os.listdir(audio_dir):\n",
    "        audio_file_path = os.path.join(audio_dir, audio_file)\n",
    "        \n",
    "        if audio_file.endswith(\".wav\"):\n",
    "            \n",
    "            if \"orig-16-44-mono\" in audio_file:\n",
    "                true_class = \"original\"\n",
    "            elif \"upscale-from-mp3-128\" in audio_file:\n",
    "                true_class = \"upscale-from-mp3-128\"\n",
    "            elif \"upscale-from-aac-128\" in audio_file:\n",
    "                true_class = \"upscale-from-aac-128\"\n",
    "            else:\n",
    "                raise ValueError(f\"Unbekannte Klasse im Dateinamen: {audio_file}\")\n",
    "            \n",
    "            if seconds:\n",
    "                chunk = get_middle_chunk(audio_file_path, seconds)\n",
    "                temp_chunk_path = \"restored_model/temp_chunk.wav\"\n",
    "                chunk.export(temp_chunk_path, format=\"wav\")\n",
    "                print(\"export\")\n",
    "                predictions = predict_with_model(loaded_model, temp_chunk_path)\n",
    "                os.remove(temp_chunk_path)\n",
    "            else:\n",
    "                predictions = predict_with_model(loaded_model, audio_file_path)\n",
    "\n",
    "            # predictions = result['predictions'].numpy()[0]\n",
    "            # class_names = [\"original\", \"upscale-from-mp3-128\", \"upscale-from-aac-128\"]\n",
    "            class_names = [\"original\", \"upscale-from-mp3-128\"]\n",
    "            predicted_class_index = np.argmax(predictions)\n",
    "            predicted_class = class_names[predicted_class_index]\n",
    "            class_probabilities = {class_names[i]: predictions[i] for i in range(len(predictions))}\n",
    "\n",
    "            # Kombiniere die \"True Class\" und \"Predicted Class\" mit den Wahrscheinlichkeiten\n",
    "            true_class_with_prob = f\"{true_class} ({class_probabilities[true_class]:.4f})\"\n",
    "            predicted_class_with_prob = f\"{predicted_class} ({class_probabilities[predicted_class]:.4f})\"\n",
    "\n",
    "            results.append({\n",
    "                \"File_Name\": audio_file,\n",
    "                \"True Class\": true_class_with_prob,\n",
    "                \"Predicted Class\": predicted_class_with_prob\n",
    "            })\n",
    "\n",
    "    # os.remove(temp_chunk_path) if seconds else None\n",
    "            \n",
    "    # Erstelle einen DataFrame aus den Ergebnissen\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    # print (df)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16, len(df) * 0.4))  # Breitere Tabelle für längere Dateinamen\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Formatieren der Zellen als Strings mit 4 Dezimalstellen\n",
    "    cell_text = [\n",
    "        [str(value) if isinstance(value, str) else f\"{value:.4f}\" for value in row]\n",
    "        for row in df.values\n",
    "    ]\n",
    "\n",
    "    # Dynamische Anpassung der Spaltenbreiten\n",
    "    table = ax.table(\n",
    "        cellText=cell_text,\n",
    "        colLabels=df.columns,\n",
    "        cellLoc=\"center\",\n",
    "        loc=\"center\",\n",
    "        colWidths=[0.5] + [0.25] * (len(df.columns) - 1)\n",
    "    )\n",
    "    \n",
    "    for row in range(len(df)):\n",
    "        cell = table[(row + 1, 0)]\n",
    "        cell.get_text().set_ha('left')\n",
    "\n",
    "    table = color_table(table, df)\n",
    "\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1.2, 1.2) \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    print(results)\n",
    "    summary = generate_summary(results)\n",
    "    summary_figure = display_summary(summary)\n",
    "\n",
    "    save_results(zip_file_path, fig, summary_figure)\n",
    "    shutil.rmtree(\"restored_model\")\n",
    "\n",
    "\n",
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
