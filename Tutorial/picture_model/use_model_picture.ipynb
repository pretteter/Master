{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import os\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  # Kein Speicherverbrauch für Plots\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import soundfile as sf\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import shap\n",
    "import gc\n",
    "from collections import Counter\n",
    "from pydub.silence import detect_silence\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import multiprocessing\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import concurrent.futures\n",
    "\n",
    "import json\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import csv\n",
    "\n",
    "\n",
    "# DATA_DIR = pathlib.Path('data')\n",
    "# TEST_DIR = pathlib.Path('data/new_test')\n",
    "\n",
    "# Globale Pfade für die Daten\n",
    "ROOT_DIR = Path('../').resolve()  # Hauptverzeichnis\n",
    "# ZIP_DIR = ROOT_DIR / 'data'  # Ordner, der die ZIP-Dateien enthält\n",
    "UNZIP_DIR = ROOT_DIR / 'Unzipped_Data_Picture'  # Zielordner für entpackte Dateien\n",
    "# TEST_DIR = ROOT_DIR / UNZIP_DIR / 'new_test'\n",
    "TEST_DIR = ROOT_DIR / UNZIP_DIR / 'final_test'\n",
    "\n",
    "session = None\n",
    "max_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip(zip_path, extract_to):\n",
    "    zip_path_str = str(zip_path)\n",
    "    \n",
    "    if not zip_path_str.endswith('.zip'):\n",
    "        zip_path_str += '.zip'\n",
    "    \n",
    "    zip_file_path = pathlib.Path(zip_path_str)\n",
    "    \n",
    "    folder_name = zip_file_path.stem \n",
    "    target_folder = pathlib.Path(extract_to) / folder_name\n",
    "    \n",
    "    if target_folder.exists():\n",
    "        print(f\"Das Verzeichnis {target_folder} existiert bereits. Überspringe das Extrahieren.\")\n",
    "    else:\n",
    "        if zip_file_path.exists():\n",
    "            print(f\"Extrahiere die Zip-Datei {zip_file_path} nach {extract_to}.\")\n",
    "            with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extract_to)\n",
    "            print(f\"Zip-Datei {zip_file_path} erfolgreich extrahiert.\")\n",
    "        else:\n",
    "            print(f\"Die Zip-Datei {zip_file_path} existiert nicht.\")\n",
    "\n",
    "def rename_audio_files(root_path):\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        parent_folder = os.path.basename(root)\n",
    "        for file in files:\n",
    "            if not file.startswith(f\"{parent_folder}_\"):\n",
    "                if file.endswith(('.wav', '.mp3')):  \n",
    "                    \n",
    "                    old_file_path = os.path.join(root, file)\n",
    "                    new_file_name = f\"{parent_folder}_{file}\"\n",
    "                    new_file_path = os.path.join(root, new_file_name)\n",
    "                        \n",
    "                    os.rename(old_file_path, new_file_path)\n",
    "        print(f\"renaming of {root_path}/{parent_folder} complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_audio_length(input_dir):\n",
    "    output_dir = input_dir.parent / f\"{input_dir.name}_normalized\"\n",
    "    if output_dir.exists():\n",
    "        print(f\"Überspringe Verarbeitung, da {output_dir} bereits existiert.\")\n",
    "        return output_dir\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    max_length = session.get(\"max_length\", 0)\n",
    "    print(f\"max_length : {max_length}\")\n",
    "    audio_files = []\n",
    "    \n",
    "    # Bestimme die längste Datei\n",
    "    for subdir, _, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                input_path = Path(subdir) / file\n",
    "                audio = AudioSegment.from_file(input_path)\n",
    "                duration = len(audio)\n",
    "                audio_files.append((input_path, audio))\n",
    "    \n",
    "    print(f\"Maximale Länge: {max_length / 1000} Sekunden\")\n",
    "    \n",
    "    # Normalisiere alle Dateien auf die maximale Länge\n",
    "    for input_path, audio in audio_files:\n",
    "        if len(audio) > max_length:\n",
    "            print(f\"⚠️ {input_path.name} ist länger als {max_length / 1000} Sekunden. Kürze Datei!\")\n",
    "            audio = audio[:max_length]  # Trimme das Audio auf max_length\n",
    "\n",
    "        padded_audio = audio + AudioSegment.silent(duration=max(0, max_length - len(audio)))\n",
    "        \n",
    "        relative_path = input_path.parent.relative_to(input_dir)\n",
    "        target_dir = output_dir / relative_path\n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "        output_path = target_dir / input_path.name\n",
    "        \n",
    "        padded_audio.export(output_path, format=\"wav\")\n",
    "        print(f\"Processed {input_path.name}: expanded to {max_length / 1000} seconds\")\n",
    "    \n",
    "    print(f\"Processing complete. Normalized files saved in {output_dir}\")\n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_file(audio_file, input_dir, output_dir, n_mels, fmin, fmax):\n",
    "    \"\"\"\n",
    "    Diese Funktion verarbeitet eine einzelne Audiodatei und berechnet das Mel-Spektrogramm.\n",
    "    \"\"\"\n",
    "    # Relativer Pfad zur Eingabedatei\n",
    "    relative_path = audio_file.relative_to(input_dir)\n",
    "    \n",
    "    # Zielpfad basierend auf der ursprünglichen Ordnerstruktur\n",
    "    target_dir = output_dir / relative_path.parent\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Lade die Audiodatei mit librosa\n",
    "    y, sr = librosa.load(audio_file, sr=44100)\n",
    "\n",
    "    # Berechne das Mel-Spektrogramm\n",
    "    # padding = 1024\n",
    "    # y = np.pad(y, (padding, padding), mode='constant')\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, fmin=fmin, fmax=fmax)\n",
    "\n",
    "    # Konvertiere das Mel-Spektrogramm in dB (logarithmische Skala)\n",
    "    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "    # Rückgabe der Daten ohne das Plotten\n",
    "    return relative_path, mel_spectrogram, sr, target_dir, audio_file.stem\n",
    "\n",
    "def generate_mel_spectrograms_with_structure(input_dir, output_dir, n_mels=256, fmin=20, fmax=44100, batch_size=25, square = False):\n",
    "    \"\"\"\n",
    "    Optimierte Funktion für die Verarbeitung von Mel-Spektrogrammen:\n",
    "    1. Berechnung wird parallelisiert.\n",
    "    2. Ergebnisse werden sequentiell geplottet, um Thread-Sicherheitsprobleme zu vermeiden.\n",
    "    3. Batches werden verwendet, um den Speicherverbrauch zu kontrollieren.\n",
    "    \"\"\"\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "\n",
    "    Überprüfen, ob die Ordnerstruktur bereits existiert\n",
    "    if output_dir.exists() and any(output_dir.rglob(\"*.png\")):\n",
    "        print(f\"Überspringe Verarbeitung, da {output_dir} bereits Mel-Spektrogramme enthält.\")\n",
    "        return\n",
    "\n",
    "    # Liste der .wav-Dateien im input_dir\n",
    "    audio_files = list(input_dir.rglob(\"*.wav\"))\n",
    "\n",
    "    if not audio_files:\n",
    "        print(\"Keine Audiodateien gefunden.\")\n",
    "        return\n",
    "\n",
    "    total_files = len(audio_files)\n",
    "    print(f\"{total_files} Audiodateien gefunden. Verarbeitung startet.\")\n",
    "\n",
    "    # Verarbeite die Dateien in Batches\n",
    "    for batch_start in range(0, total_files, batch_size):\n",
    "        batch_files = audio_files[batch_start:batch_start + batch_size]\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.close('all')\n",
    "        gc.collect()\n",
    "        print(f\"Verarbeite Batch {batch_start // batch_size + 1} von {total_files // batch_size + 1}\")\n",
    "\n",
    "        # Parallele Berechnung der Mel-Spektrogramme\n",
    "        results = []\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = [\n",
    "                executor.submit(process_audio_file, audio_file, input_dir, output_dir, n_mels, fmin, fmax)\n",
    "                for audio_file in batch_files\n",
    "            ]\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                results.append(future.result())\n",
    "\n",
    "        # Sequentielles Plotten und Speichern\n",
    "        for relative_path, mel_spectrogram_db, sr, target_dir, audio_file_stem in results:\n",
    "            mel_spectrogram_path = target_dir / f\"{audio_file_stem}_mel_spectrogram.png\"\n",
    "\n",
    "            # Überspringen, wenn das Spektrogramm bereits existiert\n",
    "            if mel_spectrogram_path.exists():\n",
    "                print(f\"Spektrogramm {mel_spectrogram_path} existiert bereits. Überspringen.\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Erstelle das Bild des Mel-Spektrogramms\n",
    "                if square:\n",
    "                    plt.figure(figsize=(2, 2))\n",
    "                    librosa.display.specshow(mel_spectrogram_db, x_axis='time', y_axis='mel', sr=sr, cmap='magma', fmin=fmin, fmax=fmax)\n",
    "                    plt.axis('off')\n",
    "\n",
    "                # Speichern des Bildes als PNG\n",
    "                    plt.savefig(mel_spectrogram_path, bbox_inches='tight', pad_inches=0, dpi=300)\n",
    "                    plt.close()\n",
    "                    print(f\"{batch_start // batch_size + 1} von {total_files // batch_size + 1}__Mel-Spektrogramm für {audio_file_stem} gespeichert in {mel_spectrogram_path}\")\n",
    "                else:\n",
    "                    height = 2000  # Höhe in Pixel\n",
    "                    width = height * 30  # Breite als Vielfaches der Höhe\n",
    "                    dpi = 100  # Auflösung\n",
    "                    figsize = (width / dpi, height / dpi)\n",
    "\n",
    "                    # Erstelle die Figure mit exakt berechneter Größe\n",
    "                    fig, ax = plt.subplots(figsize=figsize, dpi=dpi, frameon=False)\n",
    "\n",
    "                    # Spektrogramm anzeigen\n",
    "                    librosa.display.specshow(mel_spectrogram_db, x_axis='time', y_axis='mel', sr=sr, cmap='magma', fmin=fmin, fmax=fmax)\n",
    "                    ax.set_axis_off()\n",
    "\n",
    "                    # Speichern des Bildes ohne Padding oder Verzerrung\n",
    "                    plt.savefig(mel_spectrogram_path, bbox_inches='tight', pad_inches=0, dpi=dpi)\n",
    "                    plt.close(fig)\n",
    "                    print(f\"{batch_start // batch_size + 1} von {total_files // batch_size + 1}__Mel-Spektrogramm für {audio_file_stem} gespeichert in {mel_spectrogram_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Fehler beim Plotten von {audio_file_stem}: {e}\")\n",
    "            finally:\n",
    "                # Speicher freigeben\n",
    "                del mel_spectrogram_db\n",
    "                # gc.collect()\n",
    "                # print(\"batch complete\")\n",
    "\n",
    "    print(f\"Alle Mel-Spektrogramme gespeichert in {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_spectrogram(image_path, output_dir):\n",
    "    \"\"\"\n",
    "    Schneidet ein Spektrogramm in gleich große Quadrate.\n",
    "    :param image_path: Pfad zum Spektrogramm (PNG)\n",
    "    :param output_dir: Ordner zum Speichern der Segmente\n",
    "    :param segment_size: Größe jedes quadratischen Segments (Standard: 924x924)\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    trash_dir = output_dir.parent.parent / f\"{output_dir.parent.name}_trash\"\n",
    "    os.makedirs(trash_dir, exist_ok=True)\n",
    "\n",
    "    img = Image.open(image_path)\n",
    "    width, height = img.size\n",
    "    segment_size = height\n",
    "\n",
    "    num_segments = width // segment_size - 1\n",
    "    for i in range(1, num_segments):\n",
    "        left = i * segment_size\n",
    "        right = left + segment_size\n",
    "        segment = img.crop((left, 0, right, segment_size))\n",
    "        segment_array = np.array(segment)\n",
    "\n",
    "        # Berechne den Anteil an Stille (Helligkeit über einem Schwellenwert)\n",
    "        silence_threshold = 10  \n",
    "        silence_ratio = np.mean(segment_array < silence_threshold)\n",
    "\n",
    "        # Überprüfen, ob das Bild Transparenz enthält (falls RGBA-Modus)\n",
    "        transparency_ratio = 0\n",
    "        if segment.mode == 'RGBA':\n",
    "            alpha_channel = segment_array[:, :, 3]  # Der Alpha-Kanal ist der 4. Kanal (Index 3)\n",
    "            transparency_ratio = np.mean(alpha_channel == 0)  # Anteil der transparenten Pixel (Alpha == 0)\n",
    "\n",
    "        output_path = Path(output_dir) / f\"{Path(image_path).stem}_part{i}.png\"\n",
    "        if silence_ratio >= 0.7 or transparency_ratio > 0.2:\n",
    "            output_path = trash_dir / f\"{Path(image_path).stem}_part{i}.png\"\n",
    "            print(f\"Segment {i} enthält {silence_ratio * 100:.2f}% Stille und wird in den Trash {output_path} verschoben.\")\n",
    "        \n",
    "        try:\n",
    "            segment.save(output_path)\n",
    "        except IOError:\n",
    "            print(f\"Fehler beim Speichern des Segments: {output_path}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"Spektrogramm in {num_segments} Segmente geschnitten und gespeichert in {output_dir}\")\n",
    "\n",
    "\n",
    "def process_spectrograms(input_dir):\n",
    "    \"\"\"\n",
    "    Verarbeitet Spektrogramme im angegebenen Verzeichnis, ohne Unterverzeichnisse zu durchsuchen.\n",
    "    Jedes Spektrogramm wird in einem eigenen Unterordner gespeichert.\n",
    "    :param input_dir: Verzeichnis mit Spektrogrammen\n",
    "    \"\"\"\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = input_dir.parent / f\"{input_dir.name}_splits\"\n",
    "    \n",
    "    if output_dir.exists():\n",
    "        print(f\"Output directory already exists: {output_dir}. Skipping splitting.\")\n",
    "        return output_dir\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for image_path in input_dir.glob(\"*.png\"):  # Nur PNG-Dateien verarbeiten\n",
    "        subdir_name = image_path.stem.replace(\"_mel_spectrogram\", \"\")\n",
    "        target_dir = output_dir / subdir_name  # Unterordner für das Spektrogramm\n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            img = Image.open(image_path)\n",
    "            img.verify()  # Überprüft, ob das Bild beschädigt ist\n",
    "            split_spectrogram(image_path, target_dir)  # Segmente für das Spektrogramm speichern\n",
    "        except (IOError, SyntaxError):\n",
    "            print(f\"Fehler: Beschädigtes oder ungültiges Bild übersprungen: {image_path}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        if not any(target_dir.iterdir()):\n",
    "            os.rmdir(target_dir)\n",
    "            print(f\"Leerer Ordner {target_dir} wurde gelöscht.\")\n",
    "\n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_table(table, df=None):\n",
    "    # Tabelle verschönern: Farben hinzufügen\n",
    "    for (i, j), cell in table.get_celld().items():\n",
    "        if i == 0:  # Titelzeile\n",
    "            cell.set_fontsize(12)\n",
    "            cell.set_text_props(weight='bold')\n",
    "            cell.set_facecolor('#d3d3d3')  # Heller Hintergrund für die Titelzeile\n",
    "\n",
    "        elif df is not None and i > 0 and j < len(df.columns):  # Sicherstellen, dass Spalten existieren\n",
    "            if j == 0:  # Dateiname-Spalte\n",
    "                cell.set_facecolor('#f0f8ff')  # Blauer Hintergrund für die Dateinamen\n",
    "\n",
    "            elif j == 1 or j == 2:  # True Class (Spalte 1) oder Predicted Class (Spalte 2)\n",
    "                true_class = df.iloc[i - 1][\"True Class\"]  # i-1, weil i=0 die Kopfzeile ist\n",
    "                predicted_class = df.iloc[i - 1][\"Predicted Class\"]\n",
    "\n",
    "                # Überprüfe, ob die Vorhersage korrekt ist\n",
    "                if true_class == predicted_class:\n",
    "                    cell.set_facecolor('#d4edda')  # Grün für richtig\n",
    "                else:\n",
    "                    cell.set_facecolor('#f8d7da')  # Rot für falsch\n",
    "                cell.set_fontsize(10)\n",
    "\n",
    "            else:  # Wahrscheinlichkeiten und andere Werte\n",
    "                try:\n",
    "                    if float(cell.get_text().get_text()) < 0.5:\n",
    "                        cell.set_facecolor('#f8d7da')  # Rot, wenn Wahrscheinlichkeit < 0.5\n",
    "                    else:\n",
    "                        cell.set_facecolor('#d4edda')  # Grün, wenn Wahrscheinlichkeit >= 0.5\n",
    "                except ValueError:\n",
    "                    pass  # Ignoriert nicht-numerische Werte\n",
    "            cell.set_fontsize(10)\n",
    "\n",
    "    return table\n",
    "\n",
    "\n",
    "\n",
    "def generate_summary(results):\n",
    "    total_predictions = len(results)\n",
    "    correct_predictions = sum(1 for result in results if result['True Class'].split()[0] == result['Predicted Class'].split()[0])  # Vergleiche nur die Klassennamen\n",
    "    accuracy = correct_predictions / total_predictions * 100\n",
    "\n",
    "    # Extrahiere die Klassennamen ohne die numerischen Werte\n",
    "    correct_original = sum(1 for result in results if result['True Class'].split()[0] == 'original' and result['Predicted Class'].split()[0] == 'original')\n",
    "    correct_upscale = sum(1 for result in results if result['True Class'].split()[0] == 'upscale-from-mp3-128' and result['Predicted Class'].split()[0] == 'upscale-from-mp3-128')\n",
    "    \n",
    "    # Berechne die Genauigkeit nur für die jeweilige Klasse, falls es Beispiele gibt\n",
    "    original_accuracy = correct_original / sum(1 for result in results if result['True Class'].split()[0] == 'original') * 100 if sum(1 for result in results if result['True Class'].split()[0] == 'original') > 0 else 0\n",
    "    upscale_accuracy = correct_upscale / sum(1 for result in results if result['True Class'].split()[0] == 'upscale-from-mp3-128') * 100 if sum(1 for result in results if result['True Class'].split()[0] == 'upscale-from-mp3-128') > 0 else 0\n",
    "\n",
    "    summary = {\n",
    "        \"Total Correct\": f\"{correct_predictions} / {total_predictions} ({accuracy:.2f}%)\",\n",
    "        \"Original Accuracy\": f\"{original_accuracy:.2f}%\",\n",
    "        \"Upscale Accuracy\": f\"{upscale_accuracy:.2f}%\",\n",
    "        \"Overall Accuracy\": f\"{accuracy:.2f}%\",\n",
    "    }\n",
    "\n",
    "    return summary\n",
    "\n",
    "# Funktion zur Erstellung der Zusammenfassungs-Tabelle\n",
    "def display_summary(summary):\n",
    "    summary_data = [\n",
    "        [\"Total Correct\", summary[\"Total Correct\"]],\n",
    "        [\"Original Accuracy\", summary[\"Original Accuracy\"]],\n",
    "        [\"Upscale Accuracy\", summary[\"Upscale Accuracy\"]],\n",
    "        [\"Overall Accuracy\", summary[\"Overall Accuracy\"]]\n",
    "    ]\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data, columns=[f\"Metric with -sec duration\", \"Value\"])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 2))  # Größe der Tabelle\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "\n",
    "    table = ax.table(cellText=summary_df.values, colLabels=summary_df.columns, cellLoc=\"center\", loc=\"center\", colWidths=[0.5, 0.5])\n",
    "    \n",
    "    color_table(table)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return fig\n",
    "\n",
    "def calculate_accuracy(results):\n",
    "    \"\"\"\n",
    "    Berechnet die Anzahl korrekt und falsch klassifizierter Dateien basierend auf den Ergebnissen.\n",
    "    Erwartet eine Liste von Dictionaries mit den Schlüsseln 'True Class' und 'Predicted Class'.\n",
    "    \"\"\"\n",
    "    correct_predictions = sum(1 for result in results if result['True Class'] == result['Predicted Class'])\n",
    "    total_predictions = len(results)\n",
    "    accuracy = correct_predictions / total_predictions * 100\n",
    "    print(f\"Korrekte Vorhersagen: {correct_predictions}\")\n",
    "    print(f\"Falsche Vorhersagen: {total_predictions - correct_predictions}\")\n",
    "    print(f\"Genauigkeit: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "def save_results(zip_file_path, table_figure, summary_figure):\n",
    "    # Extrahiere den Dateinamen ohne Erweiterung aus dem zip_file_path\n",
    "    base_name = os.path.splitext(os.path.basename(zip_file_path))[0]\n",
    "    output_dir = os.path.dirname(zip_file_path)\n",
    "\n",
    "    # Pfade für die beiden PNG-Dateien erstellen\n",
    "    table_image_path = os.path.join(output_dir, f\"{base_name}_table.png\")\n",
    "    summary_image_path = os.path.join(output_dir, f\"{base_name}_summary.png\")\n",
    "\n",
    "    # Speichern der Haupttabelle als Bild, wenn sie nicht existiert\n",
    "    if not os.path.exists(table_image_path):\n",
    "        table_figure.savefig(table_image_path, bbox_inches=\"tight\")\n",
    "        print(f\"Haupttabelle als Bild gespeichert: {table_image_path}\")\n",
    "    else:\n",
    "        print(f\"Haupttabelle übersprungen (bereits vorhanden): {table_image_path}\")\n",
    "\n",
    "    # Speichern der Zusammenfassungstabelle als Bild, wenn sie nicht existiert\n",
    "    if not os.path.exists(summary_image_path):\n",
    "        summary_figure.savefig(summary_image_path, bbox_inches=\"tight\")\n",
    "        print(f\"Zusammenfassungstabelle als Bild gespeichert: {summary_image_path}\")\n",
    "    else:\n",
    "        print(f\"Zusammenfassungstabelle übersprungen (bereits vorhanden): {summary_image_path}\")\n",
    "\n",
    "\n",
    "def load_model_and_session(zip_file_path):\n",
    "    \"\"\"Lädt das Modell und die Session-Daten aus einer ZIP-Datei.\"\"\"\n",
    "    extract_path = \"restored_model\"\n",
    "\n",
    "    # ZIP-Datei entpacken\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "\n",
    "    # Modell laden\n",
    "    model_path = f\"{extract_path}/model.h5\"\n",
    "    loaded_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # Session-Daten laden\n",
    "    session_data_path = f\"{extract_path}/session_data.json\"\n",
    "    if os.path.exists(session_data_path):\n",
    "        try:\n",
    "            with open(session_data_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "                session_data = json.load(json_file)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Fehler: Die JSON-Datei ist fehlerhaft oder beschädigt.\")\n",
    "            session_data = {}  # Alternativ: Standardwerte setzen\n",
    "        except Exception as e:\n",
    "            print(f\"Ein unerwarteter Fehler ist aufgetreten: {e}\")\n",
    "            session_data = {}\n",
    "    else:\n",
    "        print(\"Warnung: Die Datei existiert nicht.\")\n",
    "        session_data = {}\n",
    "\n",
    "    return loaded_model, session_data\n",
    "\n",
    "\n",
    "\n",
    "def predict_with_model(model, splits_dir):\n",
    "    \"\"\"\n",
    "    Durchläuft alle Spektrogramm-Splits eines Tracks (Ordners),\n",
    "    berechnet die Vorhersagen und gibt den Durchschnitt zurück.\n",
    "    \n",
    "    :param model: Das geladene Modell für die Vorhersage\n",
    "    :param splits_dir: Pfad zum Ordner mit den Spektrogramm-Splits\n",
    "    :return: Durchschnittliche Vorhersage für den gesamten Track\n",
    "    \"\"\"\n",
    "    splits_dir = Path(splits_dir)\n",
    "    if not splits_dir.exists() or not splits_dir.is_dir():\n",
    "        raise ValueError(f\"Das Verzeichnis {splits_dir} existiert nicht oder ist kein Verzeichnis.\")\n",
    "    \n",
    "    input_shape = model.input_shape  # Erwartetes Shape (None, H, W, 3)\n",
    "    _, target_height, target_width, _ = input_shape  # Extrahiere H & W\n",
    "    print(f\"Erwartete Bildgröße: {target_height} x {target_width}\")\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for image_path in splits_dir.glob(\"*.png\"):  # Gehe durch alle Spektrogramm-Bilder\n",
    "        image = Image.open(image_path).convert(\"RGB\")  # Lade als RGB-Bild\n",
    "        image = image.resize((target_width, target_height))  # Resize auf Modellgröße\n",
    "        image_array = np.array(image)  # Normalisieren auf [0, 1]\n",
    "        input_data = tf.convert_to_tensor(image_array, dtype=tf.float32)\n",
    "        input_data = np.expand_dims(image_array, axis=0)  # Batch-Dimension hinzufügen\n",
    "        \n",
    "        # Vorhersage durchführen\n",
    "        pred = model.predict(input_data)[0]\n",
    "        print(f\"Vorhersage für {image_path}: {pred}\")\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    if not predictions:\n",
    "        raise ValueError(f\"Keine validen Spektrogramm-Splits in {splits_dir} gefunden.\")\n",
    "    \n",
    "    avg_prediction = np.mean(predictions, axis=0)  # Durchschnittliche Vorhersage berechnen\n",
    "    print(f\"Durchschnittliche Vorhersage für {splits_dir.name}: {avg_prediction}\")\n",
    "    \n",
    "    return avg_prediction\n",
    "\n",
    "\n",
    "def run(zip_file_path = \"model_results/model_(10032-resnet_model)_loss_0.319_acc_0.818_val_loss_0.472_val_acc_0.78.zip\"):\n",
    "    extract_zip(TEST_DIR, UNZIP_DIR)\n",
    "    global session\n",
    "    model, session = load_model_and_session(zip_file_path)\n",
    "    print(f\"Model loaded from: {zip_file_path}\")\n",
    "    print (f\"Session : {session}\")\n",
    "    \n",
    "    audio_dir = TEST_DIR\n",
    "\n",
    "    path = normalize_audio_length(Path(audio_dir))\n",
    "    test_mel_dir = Path(f\"{path.stem}_mel_spectrograms\")\n",
    "    generate_mel_spectrograms_with_structure(path,test_mel_dir)\n",
    "    test_mel_dir = process_spectrograms(test_mel_dir)\n",
    "\n",
    "    results = []\n",
    "    class_names = [\"original\", \"upscale-from-mp3-128\"]\n",
    "    \n",
    "    for track_dir in Path(test_mel_dir).iterdir():\n",
    "        if track_dir.is_dir():\n",
    "            if not any(track_dir.iterdir()):\n",
    "                print(f\"Überspringe leeres Verzeichnis: {track_dir}\")\n",
    "                continue\n",
    "            \n",
    "            # Bestimme die true_class aus dem Ordnernamen oder Metadaten\n",
    "            if \"orig-16-44-mono\" in track_dir.name:\n",
    "                true_class = \"original\"\n",
    "            elif \"upscale-from-mp3-128\" in track_dir.name:\n",
    "                true_class = \"upscale-from-mp3-128\"\n",
    "            elif \"upscale-from-aac-128\" in track_dir.name:\n",
    "                true_class = \"upscale-from-aac-128\"\n",
    "            else:\n",
    "                raise ValueError(f\"Unbekannte Klasse im Ordnernamen: {track_dir.name}\")\n",
    "            \n",
    "            predictions = predict_with_model(model, track_dir)\n",
    "            predicted_class_index = np.argmax(predictions)\n",
    "            predicted_class = class_names[predicted_class_index]\n",
    "            class_probabilities = {class_names[i]: predictions[i] for i in range(len(predictions))}\n",
    "            \n",
    "            true_class_with_prob = f\"{true_class} ({class_probabilities.get(true_class, 0.0):.4f})\"\n",
    "            predicted_class_with_prob = f\"{predicted_class} ({class_probabilities[predicted_class]:.4f})\"\n",
    "            \n",
    "            results.append({\n",
    "                \"Track_Dir\": track_dir.name,\n",
    "                \"True Class\": true_class_with_prob,\n",
    "                \"Predicted Class\": predicted_class_with_prob\n",
    "            })\n",
    "           \n",
    "    # Erstelle einen DataFrame aus den Ergebnissen\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    # print (df)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16, len(df) * 0.4))  # Breitere Tabelle für längere Dateinamen\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Formatieren der Zellen als Strings mit 4 Dezimalstellen\n",
    "    cell_text = [\n",
    "        [str(value) if isinstance(value, str) else f\"{value:.4f}\" for value in row]\n",
    "        for row in df.values\n",
    "    ]\n",
    "\n",
    "    # Dynamische Anpassung der Spaltenbreiten\n",
    "    table = ax.table(\n",
    "        cellText=cell_text,\n",
    "        colLabels=df.columns,\n",
    "        cellLoc=\"center\",\n",
    "        loc=\"center\",\n",
    "        colWidths=[0.5] + [0.25] * (len(df.columns) - 1)\n",
    "    )\n",
    "    \n",
    "    for row in range(len(df)):\n",
    "        cell = table[(row + 1, 0)]\n",
    "        cell.get_text().set_ha('left')\n",
    "\n",
    "    table = color_table(table, df)\n",
    "\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1.2, 1.2) \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    print(results)\n",
    "    summary = generate_summary(results)\n",
    "    summary_figure = display_summary(summary)\n",
    "\n",
    "    save_results(zip_file_path, fig, summary_figure)\n",
    "    shutil.rmtree(\"restored_model\")\n",
    "\n",
    "\n",
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
