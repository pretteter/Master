{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "# import tensorflow_io as tfio  \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import io\n",
    "import sys\n",
    "\n",
    "\n",
    "train_spectrogram_ds = None\n",
    "val_spectrogram_ds = None\n",
    "test_spectrogram_ds = None\n",
    "example_spectrograms = None\n",
    "label_names = None\n",
    "\n",
    "\n",
    "\n",
    "model = None\n",
    "history = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add `Dataset.cache` and `Dataset.prefetch` operations to reduce read latency while training the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    global train_spectrogram_ds, val_spectrogram_ds, test_spectrogram_ds    \n",
    "    train_spectrogram_ds = train_spectrogram_ds.cache().shuffle(10000).prefetch(tf.data.AUTOTUNE)\n",
    "    val_spectrogram_ds = val_spectrogram_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
    "    test_spectrogram_ds = test_spectrogram_ds.cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model, you'll use a simple convolutional neural network (CNN), since you have transformed the audio files into spectrogram images.\n",
    "\n",
    "Your `tf.keras.Sequential` model will use the following Keras preprocessing layers:\n",
    "\n",
    "- `tf.keras.layers.Resizing`: to downsample the input to enable the model to train faster.\n",
    "- `tf.keras.layers.Normalization`: to normalize each pixel in the image based on its mean and standard deviation.\n",
    "\n",
    "For the `Normalization` layer, its `adapt` method would first need to be called on the training data in order to compute aggregate statistics (that is, the mean and the standard deviation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.autograph.experimental.do_not_convert\n",
    "def build_model():    \n",
    "    input_shape = example_spectrograms.shape[1:]\n",
    "    print('Input shape:', input_shape)\n",
    "    num_labels = len(label_names)\n",
    "    print(f\"num_labels: {num_labels}\")\n",
    "\n",
    "    # Instantiate the `tf.keras.layers.Normalization` layer.\n",
    "    norm_layer = layers.Normalization()\n",
    "    # Fit the state of the layer to the spectrograms\n",
    "    # with `Normalization.adapt`.\n",
    "    norm_layer.adapt(data=train_spectrogram_ds.map(map_func=lambda spec, label: spec))\n",
    "    global model\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        # Downsample the input.\n",
    "        layers.Resizing(32, 32),\n",
    "        # Normalize.\n",
    "        norm_layer,\n",
    "        # layers.Conv2D(32, 3, activation='relu'),\n",
    "        # layers.Conv2D(64, 3, activation='relu'),\n",
    "        layers.Conv2D(16, 3, activation='relu'),\n",
    "        layers.Conv2D(32, 3, activation='relu'),\n",
    "        # layers.Conv2D(8, 3, activation='relu'),\n",
    "        # layers.Conv2D(16, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        # layers.Dropout(0.25),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        # layers.Dense(num_labels),\n",
    "        layers.Dense(num_labels, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dual_input_model():\n",
    "    input_shape_spectrogram = example_spectrograms.shape[1:]\n",
    "    input_shape_waveform = (waveform_length,)  # Setze die LÃ¤nge der Waveform\n",
    "\n",
    "    # Spektrogramm-Pfad\n",
    "    input_spectrogram = layers.Input(shape=input_shape_spectrogram, name=\"spectrogram_input\")\n",
    "    x_spec = layers.Resizing(32, 32)(input_spectrogram)\n",
    "    x_spec = layers.Conv2D(16, 3, activation='relu')(x_spec)\n",
    "    x_spec = layers.Conv2D(32, 3, activation='relu')(x_spec)\n",
    "    x_spec = layers.MaxPooling2D()(x_spec)\n",
    "    x_spec = layers.Flatten()(x_spec)\n",
    "\n",
    "    # Waveform-Pfad\n",
    "    input_waveform = layers.Input(shape=input_shape_waveform, name=\"waveform_input\")\n",
    "    x_wave = layers.Reshape((input_shape_waveform[0], 1))(input_waveform)\n",
    "    x_wave = layers.Conv1D(16, 3, activation='relu')(x_wave)\n",
    "    x_wave = layers.Conv1D(32, 3, activation='relu')(x_wave)\n",
    "    x_wave = layers.MaxPooling1D()(x_wave)\n",
    "    x_wave = layers.Flatten()(x_wave)\n",
    "\n",
    "    # Kombinieren der Features\n",
    "    combined = layers.concatenate([x_spec, x_wave])\n",
    "    x = layers.Dense(128, activation='relu')(combined)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    output = layers.Dense(num_labels, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs=[input_spectrogram, input_waveform], outputs=output)\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the Keras model with the Adam optimizer and the cross-entropy loss:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile():\n",
    "    # model.compile(\n",
    "    #     optimizer=tf.keras.optimizers.Adam(),\n",
    "    #     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    #     metrics=['accuracy'],\n",
    "    # )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),  # Wichtig: from_logits=False\n",
    "        metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model over 10 epochs for demonstration purposes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    EPOCHS = 5000\n",
    "    global history\n",
    "    \n",
    "    num_train_files = sum(1 for _ in train_spectrogram_ds.unbatch()) \n",
    "    num_val_files = sum(1 for _ in val_spectrogram_ds.unbatch())\n",
    "    \n",
    "    print(f\"Number of training files: {num_train_files}\")\n",
    "    print(f\"Number of validation files: {num_val_files}\")\n",
    "    \n",
    "    class TimeHistory(tf.keras.callbacks.Callback):\n",
    "        def on_train_begin(self, logs=None):\n",
    "            self.start_time = time.time()  \n",
    "            self.epoch_times = [] \n",
    "\n",
    "        def on_epoch_begin(self, epoch, logs=None):\n",
    "            self.epoch_start_time = time.time()\n",
    "\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            epoch_time = time.time() - self.epoch_start_time \n",
    "            self.epoch_times.append(epoch_time)\n",
    "\n",
    "            avg_epoch_time = sum(self.epoch_times) / len(self.epoch_times)\n",
    "\n",
    "            remaining_epochs = self.params['epochs'] - (epoch + 1)\n",
    "            estimated_remaining_time = remaining_epochs * avg_epoch_time\n",
    "\n",
    "            hours, rem = divmod(estimated_remaining_time, 3600)\n",
    "            minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "            print(f\"\\nEpoch {epoch + 1}/{self.params['epochs']} - Estimated time until finished: \"\n",
    "                f\"{int(hours)} hours, {int(minutes)} minutes, {int(seconds)} seconds\")\n",
    "\n",
    "\n",
    "    MAX_VAL_LOSS = 0.4\n",
    "    MAX_ACCURACY = 0.8\n",
    "    max_runs = 5  \n",
    "    run = 0  \n",
    "    \n",
    "    time_callback = TimeHistory()\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200, restore_best_weights=True)\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-6)\n",
    "    \n",
    "    while run < max_runs:\n",
    "        print(f\"Start of run {run+1}/{max_runs}\")\n",
    "        history = model.fit(\n",
    "            train_spectrogram_ds,\n",
    "            validation_data=val_spectrogram_ds,\n",
    "            epochs=EPOCHS,\n",
    "            # callbacks=[time_callback]\n",
    "            callbacks=[time_callback, early_stopping],\n",
    "            verbose = 1\n",
    "            # callbacks=[time_callback, early_stopping, reduce_lr]\n",
    "        )\n",
    "        \n",
    "        val_loss, val_accuracy = model.evaluate(val_spectrogram_ds, verbose=0)\n",
    "    \n",
    "        print(f\"Evaluated model with best weights: val_loss={val_loss}, val_accuracy={val_accuracy}\")\n",
    "    \n",
    "\n",
    "        if val_loss < MAX_VAL_LOSS and val_accuracy > MAX_ACCURACY:\n",
    "            print(f\"Run {run+1} successful with val_loss={val_loss} and val_accuracy={val_accuracy}\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Run {run+1} not successful. val_loss={val_loss}, val_accuracy={val_accuracy} - Restarting training...\")\n",
    "            run += 1\n",
    "    else:\n",
    "        print(\"Maximum number of runs reached. Best model from the last run will be used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(_train_spectrogram_ds,_val_spectrogram_ds,_test_spectrogram_ds, _label_names):\n",
    "    global train_spectrogram_ds,val_spectrogram_ds,test_spectrogram_ds, example_spectrograms, label_names, model, history\n",
    "    \n",
    "    train_spectrogram_ds = _train_spectrogram_ds\n",
    "    val_spectrogram_ds =_val_spectrogram_ds\n",
    "    test_spectrogram_ds=_test_spectrogram_ds\n",
    "    label_names = _label_names\n",
    "    \n",
    "    for example_spectrograms,_ in train_spectrogram_ds.take(1):\n",
    "        break\n",
    "    \n",
    "    init()\n",
    "    build_model()\n",
    "    # build_model_GPT()\n",
    "    compile()\n",
    "    train()\n",
    "    \n",
    "    return train_spectrogram_ds,val_spectrogram_ds,test_spectrogram_ds, model, history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
