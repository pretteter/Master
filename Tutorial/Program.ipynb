{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fluF3_oOgkWF"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-08-16T07:47:16.549129Z",
     "iopub.status.busy": "2024-08-16T07:47:16.548739Z",
     "iopub.status.idle": "2024-08-16T07:47:16.552401Z",
     "shell.execute_reply": "2024-08-16T07:47:16.551835Z"
    },
    "id": "AJs7HHFmg1M9"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYysdyb-CaWM"
   },
   "source": [
    "# Simple audio recognition: Recognizing keywords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNbqmZy0gbyE"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/audio/simple_audio\">\n",
    "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
    "    View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
    "    View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/audio/simple_audio.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPfDNFlb66XF"
   },
   "source": [
    "This tutorial demonstrates how to preprocess audio files in the WAV format and build and train a basic [automatic speech recognition](https://en.wikipedia.org/wiki/Speech_recognition) (ASR) model for recognizing ten different words. You will use a portion of the [Speech Commands dataset](https://www.tensorflow.org/datasets/catalog/speech_commands) ([Warden, 2018](https://arxiv.org/abs/1804.03209)), which contains short (one-second or less) audio clips of commands, such as \"down\", \"go\", \"left\", \"no\", \"right\", \"stop\", \"up\" and \"yes\".\n",
    "\n",
    "Real-world speech and audio recognition [systems](https://ai.googleblog.com/search/label/Speech%20Recognition) are complex. But, like [image classification with the MNIST dataset](../quickstart/beginner.ipynb), this tutorial should give you a basic understanding of the techniques involved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Go9C3uLL8Izc"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Import necessary modules and dependencies. You'll be using `tf.keras.utils.audio_dataset_from_directory` (introduced in TensorFlow 2.10), which helps generate audio classification datasets from directories of `.wav` files. You'll also need [seaborn](https://seaborn.pydata.org) for visualization in this tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T07:47:16.555919Z",
     "iopub.status.busy": "2024-08-16T07:47:16.555546Z",
     "iopub.status.idle": "2024-08-16T07:47:17.865607Z",
     "shell.execute_reply": "2024-08-16T07:47:17.864292Z"
    },
    "id": "hhNW45sjDEDe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: wrapt==1.14.1 in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pysoundfile in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.9.0.post1)\n",
      "Requirement already satisfied: cffi>=0.6 in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pysoundfile) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=0.6->pysoundfile) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tensorflow-io in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.31.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.31.0 in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-io) (0.31.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nbformat in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (5.10.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbformat) (2.20.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbformat) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from nbformat) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.20.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.2)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (306)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipykernel in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (6.29.5)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (1.8.5)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (8.27.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (8.6.2)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (6.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: decorator in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.3.2)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (306)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\prett\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipynb in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pickleshare in c:\\users\\prett\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.7.5)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install TensorFlow and Datasets\n",
    "%pip install -U -q tensorflow tensorflow_datasets\n",
    "\n",
    "# Step 2: Install Wrapt\n",
    "%pip install wrapt==1.14.1\n",
    "\n",
    "# Step 3: Install Visualization Libraries\n",
    "%pip install matplotlib seaborn\n",
    "\n",
    "# Step 4: Install PySoundFile\n",
    "%pip install pysoundfile\n",
    "\n",
    "# Step 5: Reinstall TensorFlow I/O\n",
    "# !pip uninstall -y tensorflow-io \n",
    "%pip install tensorflow-io\n",
    "# %pip install --upgrade tensorflow\n",
    "\n",
    "%pip install nbformat\n",
    "\n",
    "# Step 6: Install IPykernel\n",
    "%pip install ipykernel\n",
    "\n",
    "%pip install ipynb\n",
    "\n",
    "%pip install pickleshare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prett\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\n",
      "['c:\\\\Users\\\\prett\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python311.zip', 'c:\\\\Users\\\\prett\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib', 'c:\\\\Users\\\\prett\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\DLLs', '', 'C:\\\\Users\\\\prett\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages', 'C:\\\\Users\\\\prett\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32', 'C:\\\\Users\\\\prett\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\prett\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\prett\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311', 'c:\\\\Users\\\\prett\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import glob\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from IPython import display\n",
    "import platform\n",
    "# import tensorflow_io as tfio\n",
    "import zipfile\n",
    "import pathlib\n",
    "import shutil\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "import nbformat \n",
    "from IPython import get_ipython\n",
    "import pickle\n",
    "\n",
    "print(sys.executable)\n",
    "print(sys.path)\n",
    "\n",
    "# from shared_vars import load_vars, save_all_vars, label_names\n",
    "\n",
    "# Set directory paths\n",
    "# directory_path_database = \"../Tutorial/data/train_files\"\n",
    "# directory_path_testfiles = \"../Tutorial/data/test_files/\"\n",
    "# DATASET_PATH = 'data/train_files'\n",
    "TRAIN_DIR = pathlib.Path('data/train_files')\n",
    "TEST_DIR = pathlib.Path('data/test_files')\n",
    "DATA_DIR = pathlib.Path('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Das Verzeichnis data\\train_files existiert bereits. Ãœberspringe das Extrahieren.\n",
      "--------------------------------------------------\n",
      "Das Verzeichnis data\\test_files existiert bereits. Ãœberspringe das Extrahieren.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "renaming of data/data complete\n",
      "renaming of data/test_files complete\n",
      "renaming of data/train_files complete\n",
      "renaming of data/mp3-128kbit complete\n",
      "renaming of data/orig-wave complete\n",
      "renaming of data/upscale-16-48 complete\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "tensorflow_io ist nicht importiert\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_1-4 Inch Plug,In,Elec Guitar,Fiddles.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_1-4 Inch Plug,In,Elec Guitar,Fiddles.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_1-4 Inch Plug,In,Guitar Amp,Fiddles.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_1-4 Inch Plug,In,Guitar Amp,Fiddles.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_1-4 Inch Plug,In-Out,Elec Guitar 1.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_1-4 Inch Plug,In-Out,Elec Guitar 1.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_1-4 Inch Plug,In-Out,Elec Guitar 2.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_1-4 Inch Plug,In-Out,Elec Guitar 2.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_1-4 Inch Plug,In-Out,Elec Guitar 3.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_1-4 Inch Plug,In-Out,Elec Guitar 3.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_1-4 Inch Plug,In-Out,Guitar Amp 1.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_1-4 Inch Plug,In-Out,Guitar Amp 1.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_1-4 Inch Plug,In-Out,Guitar Amp 2.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_1-4 Inch Plug,In-Out,Guitar Amp 2.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_1-4 Inch Plug,Out,Guitar Amp.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_1-4 Inch Plug,Out,Guitar Amp.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_1-900_Hot_date.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_1-900_Hot_date.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_1-900_Physic.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_1-900_Physic.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_100Hz_sine_-20dB.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_100Hz_sine_-20dB.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_10kHz_sine_-20dB.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_10kHz_sine_-20dB.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_1kHz_sine_-20dB.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_1kHz_sine_-20dB.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_IDLE01.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_IDLE01.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_IDLE_INTERIOR01.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_IDLE_INTERIOR01.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_IGNITION01.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_IGNITION01.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER01.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER01.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER02.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER02.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER03.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER03.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER04.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER04.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER05.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER05.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER06.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER06.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER_FAST_INTERIOR01.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER_FAST_INTERIOR01.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER_INTERIOR01.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER_INTERIOR01.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER_INTERIOR02.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER_INTERIOR02.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER_INTERIOR03.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER_INTERIOR03.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER_SLOW_INTERIOR01.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER_SLOW_INTERIOR01.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER_SLOW_INTERIOR02.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER_SLOW_INTERIOR02.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER_SLOW_INTERIOR03.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER_SLOW_INTERIOR03.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER_SLOW_INTERIOR04.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_MANOUVER_SLOW_INTERIOR04.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_SLOW_SHUTDOWN_INTERIOR01.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_SLOW_SHUTDOWN_INTERIOR01.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_START01.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_4WD_HUMVEE_START01.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_500Hz_sine_-20dB.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_500Hz_sine_-20dB.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_5kHz_sine_-20dB.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_5kHz_sine_-20dB.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING01.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING01.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING02.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING02.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING03.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING03.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING04.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING04.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING05.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING05.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING06.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING06.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING07.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING07.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING08.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING08.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING09.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING09.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING10.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING10.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING11.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING11.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING12.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING12.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING13.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING13.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING14.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_ADDING_MACHINE_BURROWS_1940S_OPERATING14.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\orig-wave\\orig-wave_AMBIENCE_JAPAN_THUNDER_HEAVY_RAIN_SLIGHT_WIND_NOISE_STEREO.wav\n",
      "File 'data\\train_files\\orig-wave\\orig-wave_AMBIENCE_JAPAN_THUNDER_HEAVY_RAIN_SLIGHT_WIND_NOISE_STEREO.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 44100\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_1-4 Inch Plug,In,Elec Guitar,Fiddles.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_1-4 Inch Plug,In,Elec Guitar,Fiddles.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_1-4 Inch Plug,In,Guitar Amp,Fiddles.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_1-4 Inch Plug,In,Guitar Amp,Fiddles.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_1-4 Inch Plug,In-Out,Elec Guitar 1.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_1-4 Inch Plug,In-Out,Elec Guitar 1.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_1-4 Inch Plug,In-Out,Elec Guitar 2.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_1-4 Inch Plug,In-Out,Elec Guitar 2.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_1-4 Inch Plug,In-Out,Elec Guitar 3.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_1-4 Inch Plug,In-Out,Elec Guitar 3.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_1-4 Inch Plug,In-Out,Guitar Amp 1.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_1-4 Inch Plug,In-Out,Guitar Amp 1.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_1-4 Inch Plug,In-Out,Guitar Amp 2.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_1-4 Inch Plug,In-Out,Guitar Amp 2.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_1-4 Inch Plug,Out,Guitar Amp.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_1-4 Inch Plug,Out,Guitar Amp.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_1-900_Hot_date.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_1-900_Hot_date.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_1-900_Physic.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_1-900_Physic.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_100Hz_sine_-20dB.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_100Hz_sine_-20dB.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_10kHz_sine_-20dB.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_10kHz_sine_-20dB.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_1kHz_sine_-20dB.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_1kHz_sine_-20dB.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_IDLE01.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_IDLE01.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_IDLE_INTERIOR01.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_IDLE_INTERIOR01.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_IGNITION01.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_IGNITION01.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER01.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER01.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER02.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER02.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER03.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER03.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER04.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER04.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER05.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER05.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER06.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER06.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER_FAST_INTERIOR01.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER_FAST_INTERIOR01.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER_INTERIOR01.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER_INTERIOR01.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER_INTERIOR02.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER_INTERIOR02.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER_INTERIOR03.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER_INTERIOR03.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER_SLOW_INTERIOR01.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER_SLOW_INTERIOR01.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER_SLOW_INTERIOR02.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER_SLOW_INTERIOR02.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER_SLOW_INTERIOR03.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER_SLOW_INTERIOR03.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER_SLOW_INTERIOR04.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_MANOUVER_SLOW_INTERIOR04.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_SLOW_SHUTDOWN_INTERIOR01.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_SLOW_SHUTDOWN_INTERIOR01.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_START01.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_4WD_HUMVEE_START01.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_500Hz_sine_-20dB.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_500Hz_sine_-20dB.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_5kHz_sine_-20dB.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_5kHz_sine_-20dB.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING01.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING01.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING02.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING02.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING03.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING03.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING04.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING04.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING05.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING05.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING06.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING06.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING07.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING07.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING08.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING08.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING09.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING09.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING10.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING10.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING11.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING11.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING12.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING12.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING13.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING13.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING14.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_ADDING_MACHINE_BURROWS_1940S_OPERATING14.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n",
      "Processing file: data\\train_files\\upscale-16-48\\upscale-16-48_AMBIENCE_JAPAN_THUNDER_HEAVY_RAIN_SLIGHT_WIND_NOISE_STEREO.wav\n",
      "File 'data\\train_files\\upscale-16-48\\upscale-16-48_AMBIENCE_JAPAN_THUNDER_HEAVY_RAIN_SLIGHT_WIND_NOISE_STEREO.wav' successfully decoded!\n",
      "Audio shape: (16000, 1), Sample rate: 48000\n"
     ]
    }
   ],
   "source": [
    "def notebook_extract():\n",
    "    import ipynb.fs.defs.audio_extraction as audio_extraction\n",
    "    audio_extraction.extract_zip(TRAIN_DIR, DATA_DIR)\n",
    "    print('-' * 50)  \n",
    "    audio_extraction.extract_zip(TEST_DIR, DATA_DIR)\n",
    "    print('-' * 50)\n",
    "    print('-' * 50)  \n",
    "    audio_extraction.rename_audio_files(DATA_DIR)\n",
    "    print('-' * 50)\n",
    "    print('-' * 50)  \n",
    "    audio_extraction.process_directory(TRAIN_DIR) \n",
    "\n",
    "notebook_extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZ7GJjDvHqtt"
   },
   "source": [
    "Divided into directories this way, you can easily load the data using `keras.utils.audio_dataset_from_directory`.\n",
    "\n",
    "The audio clips are 1 second or less at 16kHz. The `output_sequence_length=16000` pads the short ones to exactly 1 second (and would trim longer ones) so that they can be easily batched.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T07:47:25.950931Z",
     "iopub.status.busy": "2024-08-16T07:47:25.950435Z",
     "iopub.status.idle": "2024-08-16T07:47:29.638136Z",
     "shell.execute_reply": "2024-08-16T07:47:29.637346Z"
    },
    "id": "mFM4c3aMC8Qv"
   },
   "outputs": [],
   "source": [
    "# file_list = tf.data.Dataset.list_files(str(TRAIN_DIR / '**/*.wav'), shuffle=False)\n",
    "\n",
    "# seconds=20\n",
    "# train_ds, val_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "#     directory=TRAIN_DIR,\n",
    "#     batch_size=64,\n",
    "#     validation_split=0.2,\n",
    "#     seed=0,\n",
    "#     output_sequence_length=16000*seconds,\n",
    "#     subset='both'\n",
    "#     )    \n",
    "# label_names = np.array(train_ds.class_names)\n",
    "# # set_label_names(np.array(train_ds.class_names))\n",
    "# print()\n",
    "# print(\"label names:\", label_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cestp83qFnU5"
   },
   "source": [
    "The dataset now contains batches of audio clips and integer labels. The audio clips have a shape of `(batch, samples, channels)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T07:47:29.642399Z",
     "iopub.status.busy": "2024-08-16T07:47:29.641722Z",
     "iopub.status.idle": "2024-08-16T07:47:29.648502Z",
     "shell.execute_reply": "2024-08-16T07:47:29.647862Z"
    },
    "id": "3yU6SQGIFb3H"
   },
   "outputs": [],
   "source": [
    "# train_ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppG9Dgq2Ex8R"
   },
   "source": [
    "This dataset only contains single channel audio, so use the `tf.squeeze` function to drop the extra axis:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T07:47:29.651841Z",
     "iopub.status.busy": "2024-08-16T07:47:29.651285Z",
     "iopub.status.idle": "2024-08-16T07:47:29.690156Z",
     "shell.execute_reply": "2024-08-16T07:47:29.689554Z"
    },
    "id": "Xl-tnniUIBlM"
   },
   "outputs": [],
   "source": [
    "# def squeeze(audio, labels):\n",
    "#   audio = tf.squeeze(audio, axis=-1)\n",
    "#   return audio, labels\n",
    "\n",
    "# train_ds = train_ds.map(squeeze, tf.data.AUTOTUNE)\n",
    "# val_ds = val_ds.map(squeeze, tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtsCSWZN5ILv"
   },
   "source": [
    "The `utils.audio_dataset_from_directory` function only returns up to two splits. It's a good idea to keep a test set separate from your validation set.\n",
    "Ideally you'd keep it in a separate directory, but in this case you can use `Dataset.shard` to split the validation set into two halves. Note that iterating over **any** shard will load **all** the data, and only keep its fraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T07:47:29.693650Z",
     "iopub.status.busy": "2024-08-16T07:47:29.693079Z",
     "iopub.status.idle": "2024-08-16T07:47:29.700058Z",
     "shell.execute_reply": "2024-08-16T07:47:29.699461Z"
    },
    "id": "u5UEGsqM5Gss"
   },
   "outputs": [],
   "source": [
    "# test_ds = val_ds.shard(num_shards=2, index=0)\n",
    "# val_ds = val_ds.shard(num_shards=2, index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T07:47:29.703324Z",
     "iopub.status.busy": "2024-08-16T07:47:29.702882Z",
     "iopub.status.idle": "2024-08-16T07:47:29.754395Z",
     "shell.execute_reply": "2024-08-16T07:47:29.753580Z"
    },
    "id": "xIeoJcwJH5h9"
   },
   "outputs": [],
   "source": [
    "# for example_audio, example_labels in train_ds.take(1):  \n",
    "#   print(example_audio.shape)\n",
    "#   print(example_labels.shape)\n",
    "  \n",
    "#   # Extrahiere Dateinamen aus dem Dataset\n",
    "# example_filenames = []\n",
    "# for filepath in file_list.take(len(example_audio)):\n",
    "#     example_filenames.append(pathlib.Path(filepath.numpy().decode('utf-8')).name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Zähler für die tatsächlichen Labels\n",
    "# actual_labels_count = 0\n",
    "\n",
    "# # Konsolenausgabe zur Überprüfung der Zuordnung\n",
    "# for i in range(len(example_filenames)):\n",
    "#     # Hole das Label aus example_labels\n",
    "#     label_index = example_labels[i].numpy()  \n",
    "#     expected_label = label_names[label_index]\n",
    "\n",
    "#     # Extrahiere das Label aus dem Dateinamen\n",
    "#     label_in_filename = example_filenames[i].split('_')[0]  # Hier anpassen, falls das Trennzeichen anders ist\n",
    "    \n",
    "#     # Zähle die tatsächlichen Labels\n",
    "#     if label_in_filename == expected_label:\n",
    "#         actual_labels_count += 1\n",
    "#         if(label_in_filename ==\"upscale-16-48\"):\n",
    "#           print('-' * 50)\n",
    "#           print(f\"Index: {i}\")\n",
    "#           print(f\"Dateiname: {example_filenames[i]}\")\n",
    "#           print(f\"Label im Dateinamen: {label_in_filename}, Erwartetes Label: {expected_label}\")\n",
    "#     else:\n",
    "#       print('!' * 50)\n",
    "#       print(f\"Index: {i}\")\n",
    "#       print(f\"Dateiname: {example_filenames[i]}\")\n",
    "#       print(f\"Label im Dateinamen: {label_in_filename}, Erwartetes Label: {expected_label}\")\n",
    "\n",
    "# # Am Ende die Gesamtanzahl der Labels ausgeben\n",
    "# print('-' * 50)  \n",
    "# print('-' * 50)\n",
    "# print('-' * 50)\n",
    "# print(f\"Anzahl der tatsächlichen Labels: {actual_labels_count}\")\n",
    "# print(f\"Anzahl der Labels im Dataset: {len(example_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mipynb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdefs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuild_database\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbuild_database\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m result \u001b[38;5;241m=\u001b[39m build_database\u001b[38;5;241m.\u001b[39mrun(\u001b[43mlabel_names\u001b[49m, example_labels, example_audio, train_ds, val_ds, test_ds, example_filenames, file_list)\n\u001b[0;32m      5\u001b[0m file_list, example_labels, example_audio, train_ds, val_ds, test_ds, label_names, example_audio, example_labels, example_filenames \u001b[38;5;241m=\u001b[39m result\n",
      "\u001b[1;31mNameError\u001b[0m: name 'label_names' is not defined"
     ]
    }
   ],
   "source": [
    "import ipynb.fs.defs.build_database as build_database\n",
    "\n",
    "result = build_database.run()\n",
    "\n",
    "file_list, example_labels, example_audio, train_ds, val_ds, test_ds, label_names, example_audio, example_labels, example_filenames = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voxGEwvuh2L7"
   },
   "source": [
    "Let's plot a few audio waveforms:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T07:47:29.765708Z",
     "iopub.status.busy": "2024-08-16T07:47:29.765166Z",
     "iopub.status.idle": "2024-08-16T07:47:31.051008Z",
     "shell.execute_reply": "2024-08-16T07:47:31.050343Z"
    },
    "id": "8yuX6Nqzf6wT"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "rows = 4\n",
    "cols = 2\n",
    "n = rows * cols\n",
    "for i in range(n):\n",
    "  print(\"i \",i)\n",
    "  # print(label_names)\n",
    "  # print(example_labels[1])\n",
    "  # print(example_labels)\n",
    "  plt.subplot(rows, cols, i+1)\n",
    "  audio_signal = example_audio[i]\n",
    "  plt.plot(audio_signal)\n",
    "  # plt.title(label_names[example_labels[i]])\n",
    "  label = label_names[example_labels[i].numpy()] \n",
    "  plt.title(f\"{i}_Label: {label} __ {example_filenames[i]}\")\n",
    "  plt.yticks(np.arange(-1.2, 1.2, 0.2))\n",
    "  plt.ylim([-1.1, 1.1])\n",
    "  \n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert waveforms to spectrograms\n",
    "\n",
    "The waveforms in the dataset are represented in the time domain. Next, you'll transform the waveforms from the time-domain signals into the time-frequency-domain signals by computing the [short-time Fourier transform (STFT)](https://en.wikipedia.org/wiki/Short-time_Fourier_transform) to convert the waveforms to as [spectrograms](https://en.wikipedia.org/wiki/Spectrogram), which show frequency changes over time and can be represented as 2D images. You will feed the spectrogram images into your neural network to train the model.\n",
    "\n",
    "A Fourier transform (`tf.signal.fft`) converts a signal to its component frequencies, but loses all time information. In comparison, STFT (`tf.signal.stft`) splits the signal into windows of time and runs a Fourier transform on each window, preserving some time information, and returning a 2D tensor that you can run standard convolutions on.\n",
    "\n",
    "Create a utility function for converting waveforms to spectrograms:\n",
    "\n",
    "- The waveforms need to be of the same length, so that when you convert them to spectrograms, the results have similar dimensions. This can be done by simply zero-padding the audio clips that are shorter than one second (using `tf.zeros`).\n",
    "- When calling `tf.signal.stft`, choose the `frame_length` and `frame_step` parameters such that the generated spectrogram \"image\" is almost square. For more information on the STFT parameters choice, refer to [this Coursera video](https://www.coursera.org/lecture/audio-signal-processing/stft-2-tjEQe) on audio signal processing and STFT.\n",
    "- The STFT produces an array of complex numbers representing magnitude and phase. However, in this tutorial you'll only use the magnitude, which you can derive by applying `tf.abs` on the output of `tf.signal.stft`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb.fs.defs.waveforms_to_spectrograms as wave_to_spec\n",
    "print(f\"label_names vor Notebook 2 {label_names}\")\n",
    "\n",
    "result = wave_to_spec.run(label_names, example_labels, example_audio, train_ds, val_ds, test_ds, example_filenames, file_list)\n",
    "\n",
    "label_names, example_labels, example_audio, train_ds, val_ds, test_ds, example_filenames, waveform, file_list, train_spectrogram_ds,val_spectrogram_ds,test_spectrogram_ds, example_spectrograms,example_spect_labels = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5KdY8IF8rkt"
   },
   "source": [
    "## Build and train the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GS1uIh6F_TN9"
   },
   "source": [
    "Add `Dataset.cache` and `Dataset.prefetch` operations to reduce read latency while training the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T07:47:33.251659Z",
     "iopub.status.busy": "2024-08-16T07:47:33.251371Z",
     "iopub.status.idle": "2024-08-16T07:47:33.266653Z",
     "shell.execute_reply": "2024-08-16T07:47:33.265952Z"
    },
    "id": "fdZ6M-F5_QzY"
   },
   "outputs": [],
   "source": [
    "train_spectrogram_ds = train_spectrogram_ds.cache().shuffle(10000).prefetch(tf.data.AUTOTUNE)\n",
    "val_spectrogram_ds = val_spectrogram_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
    "test_spectrogram_ds = test_spectrogram_ds.cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwHkKCQQb5oW"
   },
   "source": [
    "For the model, you'll use a simple convolutional neural network (CNN), since you have transformed the audio files into spectrogram images.\n",
    "\n",
    "Your `tf.keras.Sequential` model will use the following Keras preprocessing layers:\n",
    "\n",
    "- `tf.keras.layers.Resizing`: to downsample the input to enable the model to train faster.\n",
    "- `tf.keras.layers.Normalization`: to normalize each pixel in the image based on its mean and standard deviation.\n",
    "\n",
    "For the `Normalization` layer, its `adapt` method would first need to be called on the training data in order to compute aggregate statistics (that is, the mean and the standard deviation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T07:47:33.269926Z",
     "iopub.status.busy": "2024-08-16T07:47:33.269677Z",
     "iopub.status.idle": "2024-08-16T07:47:35.216670Z",
     "shell.execute_reply": "2024-08-16T07:47:35.215925Z"
    },
    "id": "ALYz7PFCHblP"
   },
   "outputs": [],
   "source": [
    "input_shape = example_spectrograms.shape[1:]\n",
    "print('Input shape:', input_shape)\n",
    "num_labels = len(label_names)\n",
    "\n",
    "# Instantiate the `tf.keras.layers.Normalization` layer.\n",
    "norm_layer = layers.Normalization()\n",
    "# Fit the state of the layer to the spectrograms\n",
    "# with `Normalization.adapt`.\n",
    "norm_layer.adapt(data=train_spectrogram_ds.map(map_func=lambda spec, label: spec))\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    # Downsample the input.\n",
    "    layers.Resizing(32, 32),\n",
    "    # Normalize.\n",
    "    norm_layer,\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_labels),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de52e5afa2f3"
   },
   "source": [
    "Configure the Keras model with the Adam optimizer and the cross-entropy loss:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T07:47:35.221273Z",
     "iopub.status.busy": "2024-08-16T07:47:35.220621Z",
     "iopub.status.idle": "2024-08-16T07:47:35.230943Z",
     "shell.execute_reply": "2024-08-16T07:47:35.230343Z"
    },
    "id": "wFjj7-EmsTD-"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f42b9e3a4705"
   },
   "source": [
    "Train the model over 10 epochs for demonstration purposes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T07:47:35.234446Z",
     "iopub.status.busy": "2024-08-16T07:47:35.233933Z",
     "iopub.status.idle": "2024-08-16T07:47:46.273388Z",
     "shell.execute_reply": "2024-08-16T07:47:46.272725Z"
    },
    "id": "ttioPJVMcGtq"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "history = model.fit(\n",
    "    train_spectrogram_ds,\n",
    "    validation_data=val_spectrogram_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjpCDeQ4mUfS"
   },
   "source": [
    "Let's plot the training and validation loss curves to check how your model has improved during training:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T07:47:46.277290Z",
     "iopub.status.busy": "2024-08-16T07:47:46.276985Z",
     "iopub.status.idle": "2024-08-16T07:47:46.551824Z",
     "shell.execute_reply": "2024-08-16T07:47:46.551207Z"
    },
    "id": "nzhipg3Gu2AY"
   },
   "outputs": [],
   "source": [
    "metrics = history.history\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,2,1)\n",
    "print(metrics)\n",
    "# plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.plot(history.epoch, metrics['loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.ylim([0, max(plt.ylim())])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss [CrossEntropy]')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "# plt.plot(history.epoch, 100*np.array(metrics['accuracy']), 100*np.array(metrics['val_accuracy']))\n",
    "plt.plot(history.epoch, 100*np.array(metrics['accuracy']))\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.ylim([0, 100])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy [%]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZTt3kO3mfm4"
   },
   "source": [
    "## Evaluate the model performance\n",
    "\n",
    "Run the model on the test set and check the model's performance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T07:47:46.555333Z",
     "iopub.status.busy": "2024-08-16T07:47:46.555094Z",
     "iopub.status.idle": "2024-08-16T07:47:46.741008Z",
     "shell.execute_reply": "2024-08-16T07:47:46.740155Z"
    },
    "id": "FapuRT_SsWGQ"
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_spectrogram_ds, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "en9Znt1NOabH"
   },
   "source": [
    "### Display a confusion matrix\n",
    "\n",
    "Use a [confusion matrix](https://developers.google.com/machine-learning/glossary#confusion-matrix) to check how well the model did classifying each of the commands in the test set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T07:47:46.744725Z",
     "iopub.status.busy": "2024-08-16T07:47:46.744463Z",
     "iopub.status.idle": "2024-08-16T07:47:47.077577Z",
     "shell.execute_reply": "2024-08-16T07:47:47.076791Z"
    },
    "id": "5Y6vmWWQuuT1"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_spectrogram_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T07:47:47.081367Z",
     "iopub.status.busy": "2024-08-16T07:47:47.080807Z",
     "iopub.status.idle": "2024-08-16T07:47:47.089747Z",
     "shell.execute_reply": "2024-08-16T07:47:47.089154Z"
    },
    "id": "d6F0il82u7lW"
   },
   "outputs": [],
   "source": [
    "y_pred = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T07:47:47.093037Z",
     "iopub.status.busy": "2024-08-16T07:47:47.092656Z",
     "iopub.status.idle": "2024-08-16T07:47:47.147352Z",
     "shell.execute_reply": "2024-08-16T07:47:47.146572Z"
    },
    "id": "vHSNoBYLvX81"
   },
   "outputs": [],
   "source": [
    "y_true = tf.concat(list(test_spectrogram_ds.map(lambda s,lab: lab)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T07:47:47.150558Z",
     "iopub.status.busy": "2024-08-16T07:47:47.150278Z",
     "iopub.status.idle": "2024-08-16T07:47:47.738680Z",
     "shell.execute_reply": "2024-08-16T07:47:47.737949Z"
    },
    "id": "LvoSAOiXU3lL"
   },
   "outputs": [],
   "source": [
    "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_mtx,\n",
    "            xticklabels=label_names,\n",
    "            yticklabels=label_names,\n",
    "            annot=True, fmt='g')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQGi_mzPcLvl"
   },
   "source": [
    "## Run inference on an audio file\n",
    "\n",
    "Finally, verify the model's prediction output using an input audio file of someone saying \"no\". How well does your model perform?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T07:47:47.742465Z",
     "iopub.status.busy": "2024-08-16T07:47:47.742161Z",
     "iopub.status.idle": "2024-08-16T07:47:48.454375Z",
     "shell.execute_reply": "2024-08-16T07:47:48.453646Z"
    },
    "id": "zRxauKMdhofU"
   },
   "outputs": [],
   "source": [
    "# # x = data_dir/'no/01bb6a2a_nohash_0.wav'\n",
    "# # x= \"../Tutorial/data/test_files/AMBIENCE_JAPAN_THUNDER_HEAVY_RAIN_SLIGHT_WIND_NOISE_STEREO.wav\"\n",
    "# x=\"../Tutorial/data/test_files/1-900_Hot_date.wav\"\n",
    "# with open(x, \"rb\") as f:\n",
    "#     x = f.read()\n",
    "\n",
    "#     print(len(x))\n",
    "# # x = tf.io.read_file(str(x))\n",
    "# x, sample_rate = tf.audio.decode_wav(x, desired_channels=1, desired_samples=16000,)\n",
    "# x = tf.squeeze(x, axis=-1)\n",
    "# waveform = x\n",
    "# x = get_spectrogram(x)\n",
    "# x = x[tf.newaxis,...]\n",
    "\n",
    "# prediction = model(x)\n",
    "# # x_labels = ['no', 'yes', 'down', 'go', 'left', 'up', 'right', 'stop']\n",
    "# x_labels=label_names\n",
    "# plt.bar(x_labels, tf.nn.softmax(prediction[0]))\n",
    "# plt.title('orig')\n",
    "# plt.show()\n",
    "\n",
    "# display.display(display.Audio(waveform, rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Test File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pfad zur WAV-Datei\n",
    "# file_path = \"../Tutorial/data/test_files/1-900_Hot_date.wav\"\n",
    "\n",
    "# # WAV-Datei im binären Modus lesen\n",
    "# with open(file_path, \"rb\") as f:\n",
    "#     # wav_data = f.read()\n",
    "#     wav_data = tf.io.read_file(file_path)\n",
    "\n",
    "# # Prüfen der Länge der gelesenen Daten\n",
    "# # print(f\"Länge der WAV-Daten: {len(wav_data)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Standard Audio Format if WAVE File Does Not Meet Expectations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_wav(input_wav, output_wav, sample_rate=16000, channels=1):\n",
    "#     \"\"\"\n",
    "#     Convert WAV file to a standardized format (Mono, 16kHz)\n",
    "#     \"\"\"\n",
    "#     command = [\n",
    "#         'ffmpeg', '-i', input_wav, '-ar', str(sample_rate), '-ac', str(channels), output_wav\n",
    "#     ]\n",
    "#     subprocess.run(command, check=True)\n",
    "\n",
    "# def load_wav_file(file_path):\n",
    "#     try:\n",
    "#         # Try to decode the WAV file\n",
    "#         with open(file_path, \"rb\") as f:\n",
    "#             wav_data = f.read()\n",
    "        \n",
    "#         audio, sample_rate = tf.audio.decode_wav(wav_data, desired_channels=1, desired_samples=16000)\n",
    "#         print(f\"File '{file_path}' successfully decoded!\")\n",
    "#         return audio, sample_rate\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error decoding WAV file '{file_path}': {e}\")\n",
    "#         print(\"Attempting to convert the file...\")\n",
    "\n",
    "#         # Path for the converted file\n",
    "#         converted_file = \"converted_temp.wav\"\n",
    "        \n",
    "#         # Convert the WAV file\n",
    "#         convert_wav(file_path, converted_file)\n",
    "        \n",
    "#         # Load the converted file and try decoding again\n",
    "#         with open(converted_file, \"rb\") as f:\n",
    "#             wav_data = f.read()\n",
    "        \n",
    "#         audio, sample_rate = tf.audio.decode_wav(wav_data, desired_channels=1, desired_samples=16000)\n",
    "#         print(f\"Converted file '{file_path}' successfully decoded!\")\n",
    "        \n",
    "#         # Remove temporary converted file\n",
    "#         os.remove(converted_file)\n",
    "        \n",
    "#         return audio, sample_rate\n",
    "\n",
    "# def process_directory(directory_path):\n",
    "#     # Find all WAV files in the directory\n",
    "#     wav_files = glob.glob(os.path.join(directory_path, \"*.wav\"))\n",
    "\n",
    "#     if not wav_files:\n",
    "#         print(\"No WAV files found in the directory.\")\n",
    "#         return\n",
    "\n",
    "#     for file_path in wav_files:\n",
    "#         print(f\"Processing file: {file_path}\")\n",
    "#         audio, sample_rate = load_wav_file(file_path)\n",
    "#         # Example: Output the shape and sample rate of the audio\n",
    "#         print(f\"Audio shape: {audio.shape}, Sample rate: {sample_rate}\")\n",
    "\n",
    "# # Example: Specify the directory with WAV files\n",
    "# #directory_path = \"../Tutorial/data/test_files\"\n",
    "# #process_directory(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_audio(file_path):\n",
    "    try:\n",
    "       audio, sample_rate = load_wav_file_basic(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not process file '{file_path}': {e}\")\n",
    "        return\n",
    "    # Entfernen der letzten Achse, falls nur ein Kanal vorliegt\n",
    "    waveform = tf.squeeze(audio, axis=-1)\n",
    "\n",
    "    print(f\"Form des Audiosignals: {waveform.shape}\")\n",
    "    print(f\"Sample Rate: {sample_rate}\")\n",
    "\n",
    "    spectrogram = get_spectrogram(waveform)\n",
    "\n",
    "    # Dimension anpassen für das Modell\n",
    "    input_tensor = spectrogram[tf.newaxis, ...]\n",
    "\n",
    "    # Vorhersage des Modells\n",
    "    prediction = model(input_tensor)\n",
    "\n",
    "    # Labels für die Vorhersage\n",
    "    x_labels = label_names  # Annahme: 'label_names' ist definiert\n",
    "\n",
    "    # Balkendiagramm der Vorhersagen anzeigen\n",
    "    plt.bar(x_labels, tf.nn.softmax(prediction[0]))\n",
    "    plt.title(f'Vorhersage für {os.path.basename(file_path)}')\n",
    "    plt.show()\n",
    "\n",
    "    # Audio im Notebook abspielen\n",
    "    display.display(display.Audio(waveform, rate=16000))\n",
    "\n",
    "def process_directory_for_visualization(directory_path):\n",
    "    wav_files = glob.glob(os.path.join(directory_path, \"*.wav\"))\n",
    "\n",
    "    if not wav_files:\n",
    "        print(\"Keine WAV-Dateien im Verzeichnis gefunden.\")\n",
    "        return\n",
    "\n",
    "    for file_path in wav_files:\n",
    "        print(f\"Verarbeite Datei: {file_path}\")\n",
    "        visualize_audio(file_path)\n",
    "\n",
    "# extract_zip(TEST_DIR, DATA_DIR)\n",
    "# rename_audio_files(DATA_DIR)\n",
    "\n",
    "process_directory_for_visualization(TEST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1icqlM3ISW0"
   },
   "source": [
    "## Export the model with preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7HX-MjgIbji"
   },
   "source": [
    "The model's not very easy to use if you have to apply those preprocessing steps before passing data to the model for inference. So build an end-to-end version:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T07:47:48.457991Z",
     "iopub.status.busy": "2024-08-16T07:47:48.457717Z",
     "iopub.status.idle": "2024-08-16T07:47:48.464142Z",
     "shell.execute_reply": "2024-08-16T07:47:48.463566Z"
    },
    "id": "2lIeXdWjIbDE"
   },
   "outputs": [],
   "source": [
    "class ExportModel(tf.Module):\n",
    "  def __init__(self, model):\n",
    "    self.model = model\n",
    "\n",
    "    # Accept either a string-filename or a batch of waveforms.\n",
    "    # YOu could add additional signatures for a single wave, or a ragged-batch. \n",
    "    self.__call__.get_concrete_function(\n",
    "        x=tf.TensorSpec(shape=(), dtype=tf.string))\n",
    "    self.__call__.get_concrete_function(\n",
    "       x=tf.TensorSpec(shape=[None, 16000], dtype=tf.float32))\n",
    "\n",
    "\n",
    "  @tf.function\n",
    "  def __call__(self, x):\n",
    "    # If they pass a string, load the file and decode it. \n",
    "    if x.dtype == tf.string:\n",
    "      x = tf.io.read_file(x)\n",
    "      x, _ = tf.audio.decode_wav(x, desired_channels=1, desired_samples=16000,)\n",
    "      x = tf.squeeze(x, axis=-1)\n",
    "      x = x[tf.newaxis, :]\n",
    "    \n",
    "    x = get_spectrogram(x)  \n",
    "    result = self.model(x, training=False)\n",
    "    \n",
    "    class_ids = tf.argmax(result, axis=-1)\n",
    "    class_names = tf.gather(label_names, class_ids)\n",
    "    return {'predictions':result,\n",
    "            'class_ids': class_ids,\n",
    "            'class_names': class_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtZBmUiB9HGY"
   },
   "source": [
    "Test run the \"export\" model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T07:47:48.467167Z",
     "iopub.status.busy": "2024-08-16T07:47:48.466892Z",
     "iopub.status.idle": "2024-08-16T07:47:48.770920Z",
     "shell.execute_reply": "2024-08-16T07:47:48.770248Z"
    },
    "id": "Z1_8TYaCIRue"
   },
   "outputs": [],
   "source": [
    "export = ExportModel(model)\n",
    "# export(tf.constant(str(data_dir/'no/01bb6a2a_nohash_0.wav')))\n",
    "export(tf.constant(str(\"../Tutorial/data/test_files/AMBIENCE_JAPAN_THUNDER_HEAVY_RAIN_SLIGHT_WIND_NOISE_STEREO.wav\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1J6Iuz829Cxo"
   },
   "source": [
    "Save and reload the model, the reloaded model gives identical output:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T07:47:48.774390Z",
     "iopub.status.busy": "2024-08-16T07:47:48.774117Z",
     "iopub.status.idle": "2024-08-16T07:47:49.775771Z",
     "shell.execute_reply": "2024-08-16T07:47:49.775108Z"
    },
    "id": "wTAg4vsn3oEb"
   },
   "outputs": [],
   "source": [
    "tf.saved_model.save(export, \"saved\")\n",
    "imported = tf.saved_model.load(\"saved\")\n",
    "imported(waveform[tf.newaxis, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3jF933m9z1J"
   },
   "source": [
    "## Next steps\n",
    "\n",
    "This tutorial demonstrated how to carry out simple audio classification/automatic speech recognition using a convolutional neural network with TensorFlow and Python. To learn more, consider the following resources:\n",
    "\n",
    "- The [Sound classification with YAMNet](https://www.tensorflow.org/hub/tutorials/yamnet) tutorial shows how to use transfer learning for audio classification.\n",
    "- The notebooks from [Kaggle's TensorFlow speech recognition challenge](https://www.kaggle.com/c/tensorflow-speech-recognition-challenge/overview).\n",
    "- The\n",
    "  [TensorFlow.js - Audio recognition using transfer learning codelab](https://codelabs.developers.google.com/codelabs/tensorflowjs-audio-codelab/index.html#0) teaches how to build your own interactive web app for audio classification.\n",
    "- [A tutorial on deep learning for music information retrieval](https://arxiv.org/abs/1709.04396) (Choi et al., 2017) on arXiv.\n",
    "- TensorFlow also has additional support for [audio data preparation and augmentation](https://www.tensorflow.org/io/tutorials/audio) to help with your own audio-based projects.\n",
    "- Consider using the [librosa](https://librosa.org/) library for music and audio analysis.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "CPU",
  "colab": {
   "collapsed_sections": [],
   "name": "simple_audio.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
