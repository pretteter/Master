{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import glob\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from IPython import display\n",
    "import pathlib\n",
    "import sys\n",
    "# import tensorflow_io as tfio  \n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "# from shared_vars import *\n",
    "\n",
    "label_names = None\n",
    "example_labels = None\n",
    "example_audio = None\n",
    "train_ds = None\n",
    "val_ds = None\n",
    "test_ds = None\n",
    "example_filenames = None\n",
    "file_list = None\n",
    "waveform = None \n",
    "\n",
    "spectrogram = None\n",
    "label = None\n",
    "\n",
    "train_spectrogram_ds = None\n",
    "val_spectrogram_ds = None\n",
    "test_spectrogram_ds = None\n",
    "example_spectrograms = None\n",
    "example_spect_labels = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert waveforms to spectrograms\n",
    "\n",
    "The waveforms in the dataset are represented in the time domain. Next, you'll transform the waveforms from the time-domain signals into the time-frequency-domain signals by computing the [short-time Fourier transform (STFT)](https://en.wikipedia.org/wiki/Short-time_Fourier_transform) to convert the waveforms to as [spectrograms](https://en.wikipedia.org/wiki/Spectrogram), which show frequency changes over time and can be represented as 2D images. You will feed the spectrogram images into your neural network to train the model.\n",
    "\n",
    "A Fourier transform (`tf.signal.fft`) converts a signal to its component frequencies, but loses all time information. In comparison, STFT (`tf.signal.stft`) splits the signal into windows of time and runs a Fourier transform on each window, preserving some time information, and returning a 2D tensor that you can run standard convolutions on.\n",
    "\n",
    "Create a utility function for converting waveforms to spectrograms:\n",
    "\n",
    "- The waveforms need to be of the same length, so that when you convert them to spectrograms, the results have similar dimensions. This can be done by simply zero-padding the audio clips that are shorter than one second (using `tf.zeros`).\n",
    "- When calling `tf.signal.stft`, choose the `frame_length` and `frame_step` parameters such that the generated spectrogram \"image\" is almost square. For more information on the STFT parameters choice, refer to [this Coursera video](https://www.coursera.org/lecture/audio-signal-processing/stft-2-tjEQe) on audio signal processing and STFT.\n",
    "- The STFT produces an array of complex numbers representing magnitude and phase. However, in this tutorial you'll only use the magnitude, which you can derive by applying `tf.abs` on the output of `tf.signal.stft`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(waveform):\n",
    "  # Convert the waveform to a spectrogram via a STFT.\n",
    "  spectrogram = tf.signal.stft(\n",
    "      waveform, frame_length=255, frame_step=128)\n",
    "  # Obtain the magnitude of the STFT.\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "  # Add a `channels` dimension, so that the spectrogram can be used\n",
    "  # as image-like input data with convolution layers (which expect\n",
    "  # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "  spectrogram = spectrogram[..., tf.newaxis]\n",
    "  return spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, start exploring the data. Print the shapes of one example's tensorized waveform and the corresponding spectrogram, and play the original audio:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def play():\n",
    "  global waveform\n",
    "  global label\n",
    "  global spectrogram\n",
    "  for i in range(3):\n",
    "    label = label_names[example_labels[i]]\n",
    "    waveform = example_audio[i]\n",
    "    spectrogram = get_spectrogram(waveform)\n",
    "\n",
    "    print('Label:', label)\n",
    "    print('Waveform shape:', waveform.shape)\n",
    "    print('Spectrogram shape:', spectrogram.shape)\n",
    "    print('Audio playback')\n",
    "    display.display(display.Audio(waveform, rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define a function for displaying a spectrogram:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(spectrogram, ax):\n",
    "  if len(spectrogram.shape) > 2:\n",
    "    assert len(spectrogram.shape) == 3\n",
    "    spectrogram = np.squeeze(spectrogram, axis=-1)\n",
    "  # Convert the frequencies to log scale and transpose, so that the time is\n",
    "  # represented on the x-axis (columns).\n",
    "  # Add an epsilon to avoid taking a log of zero.\n",
    "  log_spec = np.log(spectrogram.T + np.finfo(float).eps)\n",
    "  height = log_spec.shape[0]\n",
    "  width = log_spec.shape[1]\n",
    "  X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
    "  Y = range(height)\n",
    "  ax.pcolormesh(X, Y, log_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the example's waveform over time and the corresponding spectrogram (frequencies over time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_plot():\n",
    "    fig, axes = plt.subplots(2, figsize=(12, 8))\n",
    "    timescale = np.arange(waveform.shape[0])\n",
    "    axes[0].plot(timescale, waveform.numpy())\n",
    "    axes[0].set_title('Waveform')\n",
    "    axes[0].set_xlim([0, 16000])\n",
    "\n",
    "    plot_spectrogram(spectrogram.numpy(), axes[1])\n",
    "    axes[1].set_title('Spectrogram')\n",
    "    plt.suptitle(label.title())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create spectrogram datasets from the audio datasets:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_spec_ds(ds):\n",
    "#   return ds.map(\n",
    "#       map_func=lambda audio,label: (get_spectrogram(audio), label),\n",
    "#       num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umwandeln der Lambda-Funktion in eine reguläre Funktion\n",
    "def map_audio_label(audio, label):\n",
    "    return get_spectrogram(audio), label\n",
    "\n",
    "@tf.autograph.experimental.do_not_convert\n",
    "def make_spec_ds(ds):\n",
    "    return ds.map(\n",
    "        map_func=map_audio_label,  # Verwendung der regulären Funktion\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_spectrogram_ds = make_spec_ds(train_ds)\n",
    "# val_spectrogram_ds = make_spec_ds(val_ds)\n",
    "# test_spectrogram_ds = make_spec_ds(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the spectrograms for different examples of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example_spectrograms, example_spect_labels in train_spectrogram_ds.take(1):\n",
    "#   break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot():\n",
    "    global train_spectrogram_ds\n",
    "    global val_spectrogram_ds \n",
    "    global test_spectrogram_ds\n",
    "    global example_spectrograms\n",
    "    global example_spect_labels\n",
    "    train_spectrogram_ds = make_spec_ds(train_ds)\n",
    "    val_spectrogram_ds = make_spec_ds(val_ds)\n",
    "    test_spectrogram_ds = make_spec_ds(test_ds)\n",
    "    \n",
    "    for example_spectrograms, example_spect_labels in train_spectrogram_ds.take(1):\n",
    "        break\n",
    "    \n",
    "    rows = 4\n",
    "    cols = 2\n",
    "    n = rows*cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(16, 9))\n",
    "\n",
    "    for i in range(n):\n",
    "        r = i // cols\n",
    "        c = i % cols\n",
    "        ax = axes[r][c]\n",
    "        plot_spectrogram(example_spectrograms[i].numpy(), ax)\n",
    "        ax.set_title(f\"{i}_Label: {label} __ {example_filenames[i]}\")\n",
    "        plt.yticks(np.arange(-1.2, 1.2, 0.2))\n",
    "        plt.ylim([-1.1, 1.1])\n",
    "\n",
    "    plt.tight_layout() \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(input_label_names, input_example_labels, input_example_audio, input_train_ds, input_val_ds, input_test_ds, input_example_filenames, input_file_list):\n",
    "    global label_names, example_labels, example_audio, train_ds, val_ds, test_ds, example_filenames, file_list  # Zugriff auf die globalen Variablen\n",
    "\n",
    "    label_names = input_label_names\n",
    "    example_labels = input_example_labels\n",
    "    example_audio = input_example_audio\n",
    "    train_ds = input_train_ds\n",
    "    val_ds = input_val_ds\n",
    "    test_ds = input_test_ds\n",
    "    example_filenames = input_example_filenames\n",
    "    file_list = input_file_list\n",
    "\n",
    "    print(\"Loaded label_names (before play):\", label_names)\n",
    "    \n",
    "    play()\n",
    "    small_plot()\n",
    "    plot()\n",
    "\n",
    "    print(\"Loaded label_names (after play):\", label_names)\n",
    "    \n",
    "    return label_names, example_labels, example_audio, train_ds, val_ds, test_ds, example_filenames, waveform, file_list, train_spectrogram_ds,val_spectrogram_ds,test_spectrogram_ds, example_spectrograms,example_spect_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Notebook individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_DIR = pathlib.Path('data/train_files')\n",
    "# TEST_DIR = pathlib.Path('data/test_files')\n",
    "# DATA_DIR = pathlib.Path('data')\n",
    "\n",
    "\n",
    "# file_list = tf.data.Dataset.list_files(str(TRAIN_DIR / '**/*.wav'), shuffle=False)\n",
    "\n",
    "# seconds=20\n",
    "# train_ds, val_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "#     directory=TRAIN_DIR,\n",
    "#     batch_size=64,\n",
    "#     validation_split=0.2,\n",
    "#     seed=0,\n",
    "#     output_sequence_length=16000*seconds,\n",
    "#     subset='both'\n",
    "#     )\n",
    "\n",
    "# label_names = np.array(train_ds.class_names)\n",
    "# print()\n",
    "# print(\"label names:\", label_names)\n",
    "# play()\n",
    "# plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
